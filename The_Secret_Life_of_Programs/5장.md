# 컴퓨터 아키텍처와 운영체제

> 컴퓨터는 어떻게 프로그램과 메모리를 조직적으로 관리할까?

4장에서는 간단한 컴퓨터 시스템 설계와 CPU가 데이터와 주소 버스를 통해 메모리나 I/O 장치와 어떻게 통신하는지 살펴봤다. 하지만 컴퓨터는 가면 갈수록 복잡해졌다.

컴퓨터 아키텍처(computer architecture)는 컴퓨터의 여러 구성요소를 배치하는 방법을 의미하지, 컴퓨터 케이스가 도리스식(Doric)이나 이오니아식(Ionic)으로 꾸며져 있는 등 양식 구조를 뜻하지는 않는다. 

오랫동안 다양한 아키텍처가 시도됐다. 어떤 아키텍처가 잘 작동했고 잘 작동하지 않았는지 읽어보면 흥미진진할 것이다.

5장에서는 주로 메모리와 관련한 구조 개선을 다룬다. 최신 마이크로프로세서의 회로 사진을 보면 칩에서 가장 큰 영역이 메모리 처리에 할당됐다는 점을 알 수 있다. 그리고 명령어 집합 설계, 다른 레지스터들 전력 관리, 멋진 실행 장치 같은 구조도 간단히 살펴본다. 멀티태스킹(multitasking)에 대해서도 설명할 텐데, 멀티태스킹은 동시에 실행하는 기능이거나, 최소한 겉으로 보기에 여러 프로그램이 동시에 실행되는 것처럼 보이게 만드는 기능을 뜻한다. 여러 프로그램을 실행한다는 말은 프로그램들의 실행을 제어하기 위한 감독 프로그램인 운영체제(OS : Operating System)가 있어야 한다는 사실을 암시한다.





### 기본적인 구조 요소들

가장 흔한 두 컴퓨터 구조는 폰 노이만 구조와 하버드 구조다. 폰 노이만 구조는 위대한 과학자인 존 폰 노이만의 이름을 본뜬 것이고, 하버드 구조는 하버드 마크 1 컴퓨터의 이름을 본뜬 것이다. 두 구조의 차이는 메모리 배열 뿐이다.

```
폰 노이만 구조

		  ALU
		   |
메모리 -  실행장치
           |
          I/O
          
*ALU와 실행장치를 묶어 CPU라고 쓸 수 있음
```

```
하버드 구조

			   ALU
				|
명령어 메모리 -  실행 장치 - 데이터 메모리
				|
			   I/O
*ALU와 실행장치를 묶어 CPU라고 쓸 수 있음
```

나머지가 모두 같다면 메모리에서 동시에 명령어와 데이터를 가져올 수 없기 때문에(데이터 버스와 주소 버스가 하나 뿐이다.) 폰 노이만 구조가 약간 더 느리다. 하버드 구조는 동시에 명령어와 데이터를 가져올 수 있어서 좀 더 빠르지만 두 번째 메모리를 처리하기 위한 버스가 더 필요하다.



*프로세서 코어*

두 구조는 모두 CPU가 하나 뿐이다.CPU는 ALU, 레지스터, 실행 장치의 조합이다. 1980년대 처음 만들어진 멀티프로세서(multiprocessor) 시스템은 단일 CPU보다 훨씬 더 좋은 성능을 얻어내기 위한 방법이다. 하지만 성능을 더 높이는 게 쉽지는 않음이 드러났다. 여러 CPU를 활용할 수 있도록 프로그램을 병렬화(parallelized)하는 문제는 아주 많은 수학 계산이 필요한 경우에만 잘 작동하지만 일반적인 경우에는 풀 수 없는 문제다.

하지만 GUI를 제공하는 초기 워크스테이션(workstation)에는 여러 프로그램을 동시에 실행할 수 있다는 점이 큰 이점이다. 초기 X 윈도우 시스템은 자원을 너무 많이 잡아먹어서 윈도우 시스템을 처리하는 별도의 프로세서가 있으면 훨씬 편리했다.

반도체 회로 크기가 줄어들면서 비용도 낮아졌다. 반도체 칩은 실리콘 웨이퍼 위에 만들어지므로 그 위의 모든 요소를 작게 만들면 한 웨이퍼로 더 많은 칩을 생산할 수 있기 때문이다. CPU를 더 빠르게 만듦으로써 더 나은 성능을 달성할 수 있었다. 하지만 기계가 더 빨라지면 전력을 더 많이 사용하고 단위 면적당 열 발생은 많아졌다. 2000년경 프로세서는 전력 장벽(power wall)에 부딪힌다. 전력 장벽은 열로 인해 회로를 이루는 물질의 녹는 점 이상으로 온도가 올라가는 것을 방지하면서 회로를 소형화 고성화하기가 어려워졌다는 뜻이다.

사람들은 작아진 회로 크기를 활용한 새로운 해결책을 찾아냈다. 이전에 CPU라고 부르던 것을 프로세서 코어(processor core)라고 부른다. 이런 코어가 여럿 들어가는 멀티코어(multicore) 프로세서가 이제는 일반적으로 쓰인다.



*마이크로프로세서와 마이크로컴퓨터*

이와 별도로 물리적인 패키징에 따라 구조를 구분할 수도 있다. 메모리와 I/O가 프로세서 코어와 같은 패키지에 들어 있지 않으면 이런 프로세서를 마이크로프로세서(microprossesor)라고 부른다. 반면 모든 요소를 한 칩안에 패키징하면 마이크로컴퓨터(microcomputer)라고 부른다. 이들은 실제로 잘 정의되어 있지 않고 모호하게 쓰이는 경우가 있다. 마이크로컴퓨터가 가리키는 대상을 마이크로컨트롤러라고 부르기도하고 마이크로컴퓨터를 마이크로프로세서를 중심으로 만들어진 컴퓨터 시스템을 뜻하는 말로 사용하는 사람도 있다.

칩 안에서 메모리가 차지하는 영역이 굉장히 크기 때문에 마이크로프로세서보다 마이크로컴퓨터가 덜 강력하다. 마이크로컴퓨터는 메모리 문제가 그리 많지 않기 때문에 마이크로컴퓨터에 대해 알아보지는 않을 것이다. 하지만 아두이노 같은 것을 살펴볼 만한 가치가 있다. AVR 마이크로컴퓨터 칩을 기반으로 만들어진 하버드 구조의 컴퓨터다.

요약하면 마이크로프로세서는 보톰 큰 시스템에 들어가는 부품으로 쓰이고, 마이크로컴퓨터는 식기세척기 등에서 찾을 수 있는 단일 칩으로 된 작은 컴퓨터이다.

추가로 단일 칩 시스템(SoC : System On Chip)이라고 부르는 또 다른 변형도 존재한다. 여전히 모호하지만 통용될 만한 정의로 SoC는 더 복잡한 마이크로컴퓨터를 말한다. 상대적으로 간단한 온 칩 I/O를제공하는 대신 SoC에는 WiFi 회로 등에 더 복잡한 장치가 들어있다. 심지어 원하는 대로 커스텀화(customization)가 가능한 FPGA(field programmable gate array)를 제공하는 SoC도 있다.





### 프로시저, 서브루틴, 함수

엔지니어들은 게으름에서 비롯된 이상한 습성을 가진경우가 있다. 따라서 엔지니어들은 자신을 대신해 일을 대신해줄 무언가를 만든다. 프로그래머들이 싫어하는 일 중 하나는 똑같은 코드를 두 번 이상 작성하는 것이다. 중복된 코드를 줄이면 코드가 메모리를 덜 차지하고 코드에 버그가 있을 경우 한 군데만 고치면 된다는 장점이 있다.

함수(function) 또는 프로시저(procedure) 또는 서브루틴(subroutine)은 코드를 재사용(reuse)하는 주요 수단이다. 이 세 용어는 관심을 갖는 범위 안에서는 모두 동일한 것을 의미하며 프로그래밍 언어에 따라 이름만 다를 뿐이다.

이미 많은 프로그래밍 언어에서는 함수를 지원하고 있다.

```js
function cube(x) {
    return x*x*x
}
```

이 코드는 cube라는 함수를 만든 뒤, x라는 이름으로 파라미터(parameter)값을 받고 받은 값의 세제곱을 반환한다. 함수를 정의하고 나면 이제 다음과 같은 프로그램을 작성할 수 있다.

```js
y = cube(3)
```

이제 세제곱하는 코드를 여러번 작성하지 않아도 이 함수를 여러 번 호출(invoke, call)할 수 있다는 점이다.

어떻게 이런 코드가 작동할까? 함수를 호출하는 부분에서 함수를 실행하고 다시 원래 자리로 돌아올 방법이 필요하다. 원래 자리로 돌아오기 위해서는 어디서 함수로 들어갔는지를 기억해야 한다. 이 함수로 들어간 위치는 바로 프로그램 카운터의 값이다.

다음은 명령어 집합을 통해 함수를 호출하는 방법을 보여준다.

```
함수 호출하기
주소 | 명령어 | 피연산자  | 설명
100   pca			   프로그램 카운터 -> 누산기
101   add 	  5(즉시)   함수에서 돌아올 주소 (100+5 = 105)
102   store   200(직접) 돌아올 주소를 메모리(200)에 저장
103   load 	  3(즉시)   세제곱할 값(함수의 파라미터값)을 누산기에 넣기
104   bra	  300(직접) cute 함수를 호출(분기)
105					   함수에서 돌아온 뒤에 실행
..
200   				   함수에서 돌아올 주소를 저장하기 위해 미리 확보해둔 메모리 위치
..
300					   cute 함수 시작 부분
..
310   bra 	  200(간접) 저장했던 주소로 돌아감(간접 주소 지정을 사용해 분기)
```

우선 cube함수를 실행한 다음 돌아와야 하는(반환) 주소를 계산해야 한다. 반환 주소를 계산하기 위해 명령어를 몇 개 사용해야 하고 세제곱을 계산할 숫자를 누산기에 넣는 코드와 cube 함수를 호출하는 코드가 차지하는 주소도 감안해야 한다. 반환 주소를 계산하기 위해 명령어를 몇 개 사용해야 하고 세제곱을 계산할 숫자를 누산기에 넣는 코드와 cube 함수를 호출하는 코드가 차지하는  주소도 감안해야 한다. 따라서 반환 주소는 프로그램 시작(100번지)로부터 5개의 명령어가 지난 다음이다. 이 값을 200번지에 넣는다. 함수를 호출하면 함수가 실행되고 함수 안에 있는 모든 코드를 실행하고 나면 200번지에 있는 값을 사용해 간접 분기한다. 간접 분기를 한 결과는 (200번지에 105가 들어 있으니) 105 번지이다. 

```
: 함수 호출 예제
- 반환 주소 저장
| 함수 파라미터 -> 누산기  
| 함수로 분기	------------>        cube 함수						
								    ...
| 함수 반환 뒤에 실행 계속함 <--------	   간접 분기(반환)
|	||
-->반환 주소
```

이 과정은 상당히 많은 작업이 필요하다. 따라서 대부분의 기계에서는 이런 과정을 돕는 명령어를 제공한다. ARM 프로세서에서는 링크 레지스터를 사용해 분기(Branch with Link) 명령어가 있다. 이 명령어는 함수로 호출하는 명령어와 현재 명령어의 다음 위치를 저장하는 명령어를 하나로 합친 것이다.





### 스택

함수는 우리가 방금 본 것 같이 코드로만 이뤄지지 않는다. 함수가 다른 함수를 호출하거나 함수가 자기 자신을 호출하는 경우도 있다.

자기 자신을 호출하는 경우를 재귀(recursion)이라고 하며 재귀는 아주 쓸모가 많다. 예제로 JPEG(Joint Photographic Expert Group) 압축을 사용해 사진 크기를 감소시zlsms ruddnrk dlTek.

재귀적 분할(recursive subdivision)을 사용해 압축을 하면 이미지를 4분할 하여 각 부분을 검사한다. 이 과정을 1픽셀 조각이 생길 때 까지 계속한다.

다음은 이미지의 일부분을 처리하는 subdivide 함수를 보여준다. 의사코드(pseudocode)로 되어 있다.

```pseudocode
function
subdivide(x, y, size)
{
	IF (size != 1 AND 정사각형 안의 픽셀이 모두 다 같은 색이 아니다.) {
		half = size / 2
		subdivide(x, y, half)
		subdivide(x, y+half, half)
		subdivide(x+half, y+half, half)
		subdivide(x+half, y, half)
	}
	ELSE {
		정사각형에 대한 정보 저장
	}
}
```

subdivide 함수는 정사각형의 왼쪽 아래 꼭짓점의 x 및 y 좌표와 크기(size)를 파라미터로 취한다. subdivide 함수는 왼쪽 아래, 왼쪽 위, 오른쪽 아래, 오른쪽 위로 이미지를 색이 똑같은 정사각형 덩어리로 나눈다. 

````
									origin
									
		1      			2                       3				4
1-1 1-2 1-3 1-4	 2-1 2-2 2-3 2-4	    3-1 3-2 3-3 3-4		4-1 4-2 4-3 4-4	
````

이 그림에 있는 구조는 트리(tree)라고 부르고 수학에서 유향 비순환 그래프(directed acyclic graph : DAG)라고 부른다. 이 구조는 화살표를 따라가면서 읽으면서 읽는다. 이 구조에서 화살표는 위쪽을 가리킬 수 없기 때문에 순환이 없다. 화살표가 뻗어나가지 않는 부분 잎 노드(leaf node)라고 부르며, 나뭇가지의 맨 끝에 잎이 달려 있는 것처럼 잎 노드도 트리의 맨 마지막에 달려 있다. 이렇게 하면 최종 리프 노드의 개수가 원래 가지고 있던 픽셀의 수보다 훨씬 작아진다. 이 말은 저장해야 하는 정보가 작아진다는 것을 의미하고 이것이 바로 압축이다.

컴퓨터 매니아들은 항상 트리의 루트를 맨 위에 놓고 트리를 아래로 자라나게 그린다. 위의 트리는 각 노드에서 가지가 4개 뻗어나가기 때문에 쿼드트리(quadtree)라고 부른다. 쿼드트리는 공간 데이터 구조(spatial data structure)에 속한다. 하난 사멧(hanan samet)은 이 주제를 평생 공부했으며 이 주제를 다룬 책을 몇 권 썼다.

앞에서 본 방법으로 함수를 구현하면 문제가 생긴다. 반환값을 저장할 위치가 한 군데 뿐이기 때문에 subdivide 같이 재귀적인 함수는 이미 들어 있던 반환값을 덮어써서 되돌아갈 위치를 잃어버리기 때문에 자기 자신을 호출할 수 없다.(굳이 재귀가 아니라 프로그램이 어떤 함수를 호출하고 그 함수가 다른 함수를 호출하기만 해도 처음에 저장해둔 반환 위치가 사라지기 대문에 최초 함수를 호출했던 자리로 돌아갈 수 없게 된다.)

재귀 함수가 제대로 작동하려면 반환 주소를 여럿 저장할 수 있어야 한다. 그리고  함수에서 호출 지점으로 반환할 때 저장된 주소 중 어떤 주소를 사용할지 결정할 수 있어야 한다. 이미지를 분할하기 위해 subdivide를 호출할 때 어떤 패턴을 찾을 수 있을까? 트리 아래로 내려갈 수 있으면 항상 아래로 내려가고, 더 이상 아래로 내려갈 화살표가 없는 경우에만 옆에 있는 트리로 넘어간다. 이런 방식을 깊이 우선 순회(depth first traversal)라고 한다. 한편 옆에 있는 트리를 먼저 방문한 뒤 아래로 가는 방식을 너비 우선 순회(breadth first traversal)라고 한다. 트리에서 한 수준 내려갈 땜마다 돌아올 위치를 기억해야 한다. 일단 원래로 돌아오고나면 저장했던 위치는 더 이상 필요하지 않다.

필요한 것은 식당에 쌓아둔 접시 더미 같은 역할을 할 수 있는 장치다. 함수를 호출할 때는 반환 주소를 접시에 넣어서 접시 더미 맨 위에 넣는다. 함수 호출에서 돌아올 때는 접시 맨 위의 접시를 보고 반환 주소를 결정한 다음 접시를 제거한다. 이런 구조를 물건을 쌓아 올린다는 뜻의 스택(stack)이라고 부른다. 또는 LIFO(Last In First Out)구조라고 부른다. 스택에 물건을 푸시(push)해 두고 스택에서 물건을 팝(pop)해서 제거한다. 스택에 물건을 푸시하는 데 더 이상 들어갈 공간이 없다면 스택 오버플로(stack overflow)라고 부른다. 빈 스택에서 물건을 가져오려고 하는 경우를 스택 언더플로(stack underflow)라고 부른다.

이런 일을 소프트웨어에서도 할 수 있다. 함수 호출 예제에서 모든 함수는 자신이 (200번지를 통해) 전달받은 반환 주소를 나중에 사용하기 위해 스택에 넣을 수 있다. 다행히 스택이 아주 중요하기 때문에 대부분의 컴퓨터 하드웨어는 스택을 지원한다. 이런 지원에는 소프트웨어로 스택 오버 플로를 항상 검사하지 않아도 되도록 돕는 한계 레지스터(limit register)도 포함된다. 다음에는 소프트웨어가 이런 제한을 넘어서는 경우를 어떻게 처리하는지 보여주면서 예외(exception)에 대해서 설명한다.

스택은 단지 반환 주소만 저장하기위한 장소는 아니다. 함수는 이미지 절반 크기를 계산해 지역 변수(local variable)에 넣고 이 지역 변수에 들어 있는 값을 여덟 번 사용한다. 함수를 호출할 때 이 지역 변숫값을 그냥 덮어쓰면 안 된다. 대신, 지역 변수도 스택에 저장해야 한다. 이렇게 하면 각각의 함수 호출이 서로 독립적이게 된다. 이렇게 함수가 호출될 때마다 스택에 저장되는 데이터의 모음을 스택 프레임(stack frame)이라고 부른다. 

```
			   스택
subdivide(0,0,8) 반환 주소, half = 4
subdivide(4,4,4) 반환 주소, half = 2
subdivide(4,4,2) 반환 주소, half = 1
subdivide(5,5,1) 반환 주소, half = 1
```

각 함수 호출이 반환 주소와 지역 변수를 포함하는 새로운 스택 프레임을 만든다는 사실을 볼 수 있다.

포스(forth)나 포스트스크립트(PostScript)같은 몇몇 언어와 HP 계산기 몇 가지는 스택 기반 언어다. 스택은 컴퓨터 언어에만 한정되지 않는다.





### 인터럽트

실행 중인 프로그램을 잠깐 중단 시켜서 주의를 기울여야 하는 외부의 요소에 대응할 수 있게 만들 방법이 필요하다. 이제 실행 장치에 새로운 하드웨어 기능을 추가할 때다.

요즘 쓰이는 프로세서 대부분은 인터럽트(interrupt) 시스템이 들어간다. 인터럽트 시스템은 적절한 신호가 들어오면 CPU 실행을 잠깐 중단 시킬수 있는 핀이다 핀(pin)은 전기적 접점을 뜻하는 말이다. 칩에는 핀처럼 보이는 부품이 많았지만 크기가 줄어듦에 따라 다른 방식도 쓰이기 시작했다. 많은 프로세서 칩에는 통합 주변장치(integrated peripheral)가 들ㅇ어 있고 (이런 장치를 on-chip I/O 장치라고도 한다.) 이런 장치들은 내부적으로 인터럽트 시스템에 연결되어 있다.

이제 인터럽트 시스템이 작동되는 방식을 살펴보자. CPU가 주의를 기울여야 하는 장치는 인터럽트 요청(interrupt request)를 생성한다. 프로세서는 (보통) 현재 실행중인 명령어를 끝까지 실행한다. 그 후 프로세서는 현재 실행 중인 프로그램을 잠시 중단시키고 인터럽트 핸들러(interrupt handler)라는 전혀 다른 프로그램을 실행한다. 인터럽트 핸들러가 필요한 작업을 다 마치고 나면 원래 실행 중이면 프로그램이 중단된 위치부터 다시 실행을 계속한다. 인터럽트 핸들러는 함수다.

이 과정에서 고려해야 할 요소가 몇가지 있다. 첫째, 인터럽트에 대한 응답 시간(response time)이다. 인터럽트 처리가 너무 길어지게 되면 원래 해야할 일을 못할 수 있다. 그래서 인터럽트 처리는 제 시간 안에 끝내야 한다. 둘 째 인터럽트를 서비스하고 나중에 원래대로 돌아오기 위해서는 현재 상태를 저장할 방법이 필요하다. 예를들어 인터럽트가 걸린 시점에서 프로그램이 레지스터에 어떤 값을 저장하고 있었다면 인터럽트 핸들러는 그 레지스터를 저장했다가 나중에 원래 프로그램으로 돌아오기 전에 복구를 해주어야 한다.

인터럽트 시스템은 서비스 후 돌아올 위치를 스택에 저장한다. 인터럽트 핸들러는 자신이 덮어쓸 레지스터를 모두 저장해야 하는 책임이 있다. 이렇게 하면 인터럽트 핸들러가 저장해야 하는 요소를 최소화 해서 가장 빨리 인터럽트를 서비스할 수 있다.

어떻게 인터럽트 핸들러 위치를 찾을 수 있을까? 보통은 인터럽트 핸들러 주소를 저장하기로 약속한 메모리 주소가 존재한다. 이 주소에는 인터럽트 벡터가 들어 있고 각 인터럽트 벡터는 CPU가 지원하는 각 인터럽트에 대한 핸들러 주소를 지정한다. 인터럽트 벡터(interrupt vector)는 단지 메모리 위치를 가리키는 포인터일 뿐이다. 벡터는 화살표와 같다. 인터럽트가 일어나면 컴퓨터는 인터럽트 벡터에 저장된 주소를 살펴보고 제어를 그 주소로 옮긴다. (즉 프로그램 카운터를 인터럽트 벡터에 저장된 값으로 설정한다.)

많은 기계가 물리적인 주소를 벗어나는 주소를 사용하려고 시도하거나, 스택 오버플로가 일어나는 등의 예외 상황에 대한 인터럽트 벡터를 제공한다. 예외를 인터럽트 핸들러를 통해 처리하면 인터럽트 핸들러 안에서 문제를 해결함으로써 오류가 생긴 프로그램이 계속 실행될 수 있는 경우도 있다.

전형적인 경우 여러가지 종류의 인터럽트 제어가 가능하다. 예를들어 인터럽트를 켜거나 끌 수 있다. 인터럽트를 중단 시킬 수 있는 마스크(mask)가 있는 경우가 자주 있다. 인터럽트가 많이 있는 기기에서는 인터럽트 간의 우선순위(priority)가 있어서 더 중요한 인터럽트를 더 먼저 처리하게 해준다. 이 말은 우선순위가 낮은 인터럽트를 서비스하는 인터럽트 핸들러는 더 높은 인터럽트가 발생하면 일시 중단 될 수도 있다는 것이다. 대부분의 기계에는 일정 시간이 지나면(혹은 간격으로) 인터럽트를 발생시킬 수 있는 내장 타이머도 하나 이상 들어있다.

운영체제는 다른 일반 프로그램들은 접근할 수 없는 물리적(HW) 인터럽트에 접근할 수 있는 경우가 종종 있다. 운영체제는 가상(virtual) 인터럽트나 소프트웨어 인터럽트 시스템을 제공하기도 한다. 예를 들어 유닉스 운영체제는 시그널 메커니즘을 제공한다. 최근 개발된 시스템은 이를 '이벤트'라고 부른다.



### 상대 주소 지정

여러 프로그램을 동시에 실행하려면 어떻게 해야할까? 우선 각 프로그램을 서로 전환시켜 줄 수 있는 일종의 관리자 프로그램이 필요하다. 이런 프로그램을 운영체제 또는 운영체제 커널(kernel : 중심)이라고 한다. 우리는 OS와 OS가 관리하는 프로그램을 구분하기 위해 OS를 시스템 프로그램이라고 부르고 다른 모른 프로그램을 사용자(user) 프로그램이나 프로세스(process)라고 부른다. 

```
간단한 운영체제

1.사용자 프로그램을 메모리로 읽기
2.상태 복원
3.사용자 프로그램 실행
4.타이머 인터럽트
5.사용자 프로그램 중단
6.상태 저장(1번으로 돌아감)
```

여기서 OS는 타이머를 사용해 사용자 프로그램을 전환시켜줄 때가 됐는지 판단한다. 이런 식으로 사용자 프로그램의 실행 시간을 조정하는 스케줄링 기법을 시분할(time sclicing)이라고 부른다. 시분할 방식에서는 시간을 정해진 간격으로 나누고, 정해진 시간 간격 동안 사용자 프로그램을 실행한다. 사용자 프로그램 상태(state) 또는 문맥(context)은 레지스터의 상태와 프로그램이 사용 중인 메모리의 상태를 뜻한다. 이에는 메모리에는 스택도 포함된다.

이런 방법은 잘 작동하지만 아주 느리고 프로그램을 메모리로 불러들일려면 시간이 걸린다. 프로그램을 메모리로 불러오되 프로그램에게 각기 다른 공간을 허용할 수 있으면 훨씬 빠르게 시분할 실행이 가능하다.

```
주소  프로그램
 0   프로그램1
 1   프로그램2
 2   프로그램3
```

위의 예시에서 사용자 프로그램은 하나씩 차례로 메모리에 올라간다. 하지만 어떻게 이런 프로그램이 작동할 수 있을 까 '주소 지정 모드'를 설명할 때 우리가 예로 든 컴퓨터는 절대 주소 지정(absolute addressing)을 사용햇다. 절대 주소 지정은 명령어 주소가 특정 메모리 주소를 가리킨다는 뜻이다. 따라서 1번지에서 실행되도록 만들어진 프로그램을 2번지에서 사용하려고 읽어들이면 실행되지 않을 것이다.

어떤 컴퓨터들은 이런 문제를 인덱스 레지스터(index register)를 추가해 해결한다. 인덱스 레지스터를 사용하면 인덱스 레지스터의 값을 명령어에 들어있는 주소와 더해서 유효주소(effective address)를 계산한다. 사용자 프로그램이 1번지에서 실행되도록 만들어졌다면 OS는 프로그램을 3번지에서 실행하기 위해 인덱스 레지스터를 2로 설정할 수 있다.

```
주소 + 인덱스 레지스터 = 유효 주소
```

이 문제를 해결하는 또 다른 방법은 상대 주소 지정(relative addressing)을 사용하는 것이다. 상대 주소 지정은 명령어에 들어 있는 주소를 0(대부분의 기계에서 시작 주소는 0이다.)부터 시작하는 위치로 해석하지 않고 명령어의 주소를 기준으로 하는 상대 주소로 해석한다. 만약  프로그램이 들어가 있는 명령어의 위치가 1이고 100이라는 주소를 지정하려면 값이 99가 되어야 한다. 100이라는 주소는 1로부터 99만큼 떨어져 있기 때문이다. 마찬가지로 주소 104로 분기하는 명령어가 상대주소록 표현하려면 -4가 들어가야 한다.  기계어에서 이를 해석하지는 않고 프로그래밍 언어 도구들이 계산을 알아서 해준다. 상대 주소 지정을 사용하면 프로그램을 메모리에 원하는 위치로 자유롭게 재배치(relocate) 할 수 있다.





### 메모리 관리 장치

멀티태스킹은 필수품이 되었다. 이제 모든 것은 인터넷에 연결되어 있고 통신 작업은 계속해서 백그라운드(background)에서 실행 돼야 하기 때문에 멀티태스킹이 필수다. 인덱스 레지스터와 상대 주소 지정이 멀티태스킹에 도움이 될 수 있지만 이만으로는 충분하지 않다. 프로그램에 버그가 있다면 기존에 사용되던 메모리를 덮어쓰거나 OS의 메모리를 덮어쓰면 큰 일이 벌어 질 것이다. 각 프로그램을 분리해서 이런 시나리오가 아예 불가능하게 할 수 있으면 좋다. 이를 위해 대부분의 프로세서에는 메모리 관리 장치(MMU : Memory Management Unit)가 들어있다. MMU는 아주 복잡한 하드웨어이다.

MMU가 들어 있는 시스템있는 가상 주소 (virtual address)와 물리주소(physical address)를 구분한다. 밑처럼 프로글매은 가상 주소를 사용해 작성되고 MMU는 가상 주소를 물리 주소로 변환해준다.

```
프로그램 -가상 주소> 메모리 관리 장치 -물리 주소> 메모리
```

MMU와 인덱스 레지스터는 어떤 차이가 있을까? MMU의 가상 주소 범위는 물리적 메모리 주소보다 큰 경우가 많다. MMU는 가상 메모리 주소를 두 부분으로 나눈다. 주소의 하위(LSB) 부분은 물리적 주소 범위와 같다. 상위(MSB)쪽 부분은 페이지 테이블(page table)이라는 RAM 영역을 통해 주소를 변환(translation)한다. 

````
가상 주소 MSB ->주소 디코더 -> 실제 주소의 MSB
가상 주소 LSB -> 실제 주소의 LSB
````

위 예제에서 메모리는 256 바이트 크기의 페이지(page)로 분한된다. 페이지 테이블에는 각 페이지가 물리 메모리상에서 차지하는 실제 위치 정보가 들어 있다. 이를 통해 1000번지(가상 메모리)에서 시작하는 프로그램을 2000번지(물리 메모리)나 다른 곳에 넣을 수 있다. 물론 모든 내용이 페이지 경계(page boundary)에 들어 있어야 한다. 그리고 프로그램 입장에서는 가상 메모리가 연속적인 것처럼 보이지만 실제 물리 메모리 상의 위치는 연속적일 필요가 없다. 심지어 프로그램이 실행되는 도중에 프로그램이 위치한 물리적 메로리 주소가 바뀔 수도 있다. 프로그램들이 서로 협력하는 경우에는 여러 프로그램 중 가상 메모리 중 일부가 같은 물리 메모리를 함께 사용하는 공유 메모리(shared memory)기능을 제공할 수도 있다. 이제 페이지 테이블의 내용이 프로그램 문맥의 일부분이 된다는 사실에 유의하라.

이제 페이지 테이블이 그냥 메모리의 일부분처럼 보인다는 사실을 깨달았을 것이다. 

예제에선느 16비트 주소를 사용한다. 64비트 기계를 사용하는 최근 기계를 사용한다면 어떨까? 주소를 절반씩 두 부분으로 나누면 4GiB의 페이지 테이블이 필요하고 페이지 크기도 4GiB가 필요할 것이다. 현재도 물리적 메모리가 4GiB 정도 밖에 안 되는 시스템이 많이 있으므로 이런 페이지 구성은 그리 쓸모 있지 않다. 페이지 크기를 좀 더 작게 만들 수 있을 것이다. 하지만 페이지 크기를 줄이면 페이지 테이블 크기가 늘어난다. 이를 해결할 방법이 필요하다.

현대적 프로세서의 MMU는 페이지 테이블 크기가 정해져 있다. 전체 페이지 테이블 항목(page table entry)은 주 메모리에 저장되거나 주 메모리가 부족한 경우 디스크에 저장된다. MMU는 페이지 테이블 항목 중 일부를 필요할 때만 자신의 페이지 테이블로 읽어 들인다.

일부 MMU 설계는 페이지 테이블에 제어 비트를 추가 제공한다. 이런 제어 비트의 예로 실행 불가 비트(no execude bit)를 들 수 있다. 어떤 페이지에 대해 실행 불가 비트가 설정되어 있으면 CPU가 이 페이지에 있는 명령어를 실행할 수 없다. 따라서프로그램이 실수로 자기 데이터를 실행하는 경우를 방지할 수 있다. 데이터 부분을 실행할 수 있으면(프로그램을 실행 시점에 마음대로 바꿔 쓸 수 있기 때문에) 보안 문제가 생길 수도 있다. 또 다른 일반적인 제어 비트로는 페이지를 읽기 전용(read only)으로 만드는 비트가 있다.

프로그램이 물리적 메모리에 연관되지 않은 주소에 접근하면 페이지 폴드(page fault) 예외가 발생한다. 이런 동작은 스택 오버플로 등이 일어날 때 유용하게 쓰일 수 있다. 스택 오버플로가 발생하면 스택 범위를 벗어나는 주소에 접근하므로 페이지 폴트가 발생하고 이 예외가 발생하면 OS는 실행 중인 프로그램을 중단시키는 대신 MMU가 추가 메모리를 할당하게 해서 스택 공간을 늘리고 사용자 프로그램 실행을 계속할 수 있다.

MMU로 인해 폰 노이만 구조와 하버드 구조의 구분이 의미 없어졌다. 단일 메모리 버스만 사용하는 폰 노이만 구조의 시스템도 명령어 메모리와 데이터 메모리를 분리해 제공할 수 있다.





#### 가상 메모리

운영체제는 희소한 하드웨어 자원을 사용하려고 경합하는 프로그램들 사이의 자원 분배를 관리한다. OS가 CPU 자체에 대한 접근을 관리하는 방식을 살펴봤다. 메모리도 역시 OS가 관리하는 자원이다. OS는 MMU를 사용해 사용자 프로그램에게 가상 메모리(virtual memory)를 제공한다.

MMU가 프로그램의 가상 주소를 물리 메모리 주소로 변환해준다는 사실을 살펴봤다. 하지만 가상 메모리는 그 이상이다. 페이지 폴트 메커니즘으로 인해 프로그램은 필요한 만큼(가상 메모리 주소 범위 내에서) 많은 메모리가 있다고 생각할 수 있게 됐다. 요청 받은 메모리가 사용 가능한 (물리적) 메모리의 크기보다 크면 어떻게 될까? OS는 현재 필요하지 않은 메모리 페이지를 더 느리지만 더 용량이 큰 대용량 저장장치인 디스크로 옮긴다.(이를 스왑 아웃(swap out)이라 한다.) 이런 스왑 아웃한 페이지에 프로그램이 접근하면 운영체제는 필요한 메모리 공간을 확보하고 요청받은 페이지를 다시 메모리로 불러들인다.(이렇게 디스크에서 메모리로 페이지를 읽어오는 동작을 스왑 인(swap in)이라 한다.) 이런 식으로 페이지를 처리하는 것을 요구불 페이징(demand paging)이라고 부른다. 한 페이지가 스왑 아웃된 가상 메모리 시스템을 보여준다.

````
가상 메모리 | MMU 페이지 테이블 | 물리 메모리    | 디스크 스왑 영역
0    -------    0     -------  0
1    -------    1     -------  2
2    -------    2     -------  5
..
n    -------    n     -------  swap out     ------ n
````

스와핑(swapping, 스왑 인이나 스왑 아웃)이 일어나면 시스템 성능이 크게 저하된다. 하지만 메모리가 부족해서 프로그램을 실행도 못하는 것보다는 느리더라도 스와핑을 통해 프로그램을 실행하는 편이 더 낫다. 가상 메모리 시스템은 성능 저하를 막기 위해 다양한 기법을 활용한다. 이런 기법 중 하나는 페이지 접근을 추적해서 스왑 아웃할 페이지를 결정하는 최소 최근 사용(LRU : Least Recently Used) 알고리즘이다. 이 알고리즘을 사용하면 최근에 가장 자주 사용된 페이지는 물리 메모리에 그대로 남겨두고 최근에 가장 덜 사용한 페이지를 스왑아웃한다. 





### 시스템 공간과 사용자 공간

멀티태스킹 시스템은 모든 프로그램에게 자신이 컴퓨터 안에서 실행되는 유일한 프로그램이라는 환상을 심어준다. MMU는 각 프로세스에게 자신만의 메모리 주소 공간을 제공해서 이런 황상을 키워준다. 하지만 I/O 장치가 끼어들면 이런 환상을 유지하기가 힘들어진다. 예를 들어 운영체제가 타이머 장치를 사용해서 실행 중인 프로그램을 다른 프로그램으로 전환할 시점을 알아낸다. 운영체제는 초당 발생할 인터럽트 횟수에 맞춰 타이머를 설정한다. 하지만 사용자 프로그램이 이 타이머 설정을 한 시간에 한 번만 인터럽트 하도록 변경하면 모든 것이 예상과 다르게 작동한다. 마찬가지로 사용자 프로그램이 MMU의 설정을 마음대로 바꿀 수 있다면 MMU가 프로그램을 서로 격리시키지 못할 것이다. 

여러 CPU는 이런 문제를 해결할 수 있는 추가 하드웨어를 제공한다. CPU에는 컴퓨터가 시스템 모드에 있는 지 유저 모드에 있는 지 결정하는 비트가 어떤 레지스터 안에 들어 있다. I/O를 처리하는 명령어 등 일부 명령어는 특권(privileged) 명령어라서 오직 시스템 모드에서만 실행할 수 있다. 트랩(trap)이나 시스템 콜(system call)이라고 부르는 특별한 명려어를 통해 사용자 모드에서 실행 중인 프로그램이 시스템 모드 프로그램(즉 운영체제)에게 요청을 보낼 수 있다.

이런 방식에는 몇 가지 장점이 있다. 첫째 이 방식은 사용자 프로그램으로부터 운영체제를 보호하고, 사용자 프로그램을 다른 사용자 프로그램으로부터 보호한다. 둘째 사용자 프로그램이 MMU 등의 몇몇 요소에 손을 댈 수 없기 때문에 운영체제가 프로그램에 대한 자원할당을 전적으로 제어할 수 있다. 하드웨어 예외는 오직 시스템 공간에서만 처리된다.

핸드폰 노트북, 데스크톱에 쓰려고 작성한 프로그램은 사용자 공간에서 실행된다. 시스템 공간에서 실행되는 프로그램에 손을 대기 위해서는 아주 뛰어난 프로그래머가 될 필요가 있다.





### 메모리 계층과 성능

과거에는 CPU와 메모리가 같은 속도로 작업했고 컴퓨터 세계는 평온했다. 하지만 CPU가 더더욱 빨라졌지만 메모리가 빨라지지는 못해서 CPU보다 속도가 뒤쳐지기 시작했다. 컴퓨터 구조 설계 시 빠른 CPU가 느린 메모리를 기다리느라고 아무 일도 하지 않는 경우를 줄이기 위해 온갖 방법을 다 쓰기 시작했다.

가상 메모리와 스와핑은 메모리 계층(memory hierarchy)라는 개념을 소개했다. 사용자 프로그램에게 모든 메모리는 같아보이지만 메모리 시스템 내부에서 일어나는 일은 시스템 성능에 큰 영향을 끼친다.

컴퓨터는 빠르다. 컴퓨터는 1초에 수십억 개의 명령어를 실행할 수 있다. 하지만 실행할 명령어가 도착하기를 CPU가 기다리거나 메모리에 데이터를 읽거나 쓸 때까지 CPU가 기다려야 한다면 그렇게 많은 일을 해낼 수는 없다.

프로세서에 레지스터라는 빠르고 비싼 메모리가 들어 있다는 사실을 살펴봤다. 초기 컴퓨터에는 레지스터가 몇 개 안 들어 있었다. 하지만 최근에는 수 백개가 들어있다. 하지만 일반적으로 레지스터가 전체 메모리에서 차지하는 비율은 점점 작아져 왔다. 프로세서는 보통 RAM으로 이뤄진 주 메모리(main memory)와 통신하는 데 주 메모리는 프로세서보다 1/10 정도밖에 속도가 나지 않는다. 디스크 드라이브 등의 대량 저장장치는 프로세서보다 백 만배 느릴 수도 있다. 이를 이해하기 위해 제프 베리맨이 쓴 페이징 게임을 보면 모든 게 어떻게 작동하는 지에 대한 흥미로운 설명을 볼 수 있다.

세부 사항을 상당 부분 생략한 뒤 CPU가 주 메모리보다 10배 더 빠르게 작동한다고 하자. 이를 해석하면 CPU가 메모리를 기다리느라 많은 시간을 소비해야 한다는 뜻이다. 이를 해결하기 위해 캐시(cache)라는 하드웨어(아주 빠른 온 칩 메모리)를 CPU에 추가한다. 

열로 DRAM을 읽을 때 행으로 읽는 것보다 더 빠르다는 사실을 볼 수 있다. 프로그램이 작동하는 방식을 관찰하면, 분기가 없는 경우 프로그램 메모리를 순서대로 읽어온다는 사실을 알 수 있고, 프로그램이 사용하는 데이터가 한데 모여 있는 경우가 많다는 사실도 알 수 있다. 이런 현상을 이용해 CPU 메모리 컨트롤러(memory controller) 하드웨어는 메모리에서 연속된 열에 있는 데이터를 한꺼번에 가져온다. 대부분은 연속된 위치에 있는 데이터가 필요하기 때문이다. 메모리에 접근하는 패턴이 순차적이 아니어서 캐시 실패(cache miss)가 일어나더라도 CPU는 고속 메모리 접근 모드가 가능하기 때문에 좀 더 유리하다. 캐시 실패는 CPU가 캐시에서 어떤 내용(어떤 주 메모리 주소에 들어 있는 내용)을 찾았는데 캐시에 그 데이터가 없어서 메모리를 읽어야 하는 경우를 말한다. 비슷하게 캐시 적중(cache hit)은 CPU가 원하는 내용을 캐시에서 찾은 경우를 뜻한다. 

캐시 메모리에도 몇 가지 계층이 있다. 모든 캐시가 같은 칩 안에 존재하는 경우에도 CPU에서 멀어질수록 캐시는 더 느려지고 커진다. 이를 L1, L2, L3 캐시라고 부른다. (L은 레벨)  그리고 디스패처(dispatch)는 여러가지 내용들을 채워 넣거나 내용을 꺼내는 일을 담당하는 아주 큰 논리 회로다. 실제로 CPU 칩에서 이들이 차지하는 영역이 상당히 크다. 그림은 메모리 계층을 간략히 보여준다.

```
fast & expensive CPU
								 레지스터
								 L1 캐시
								 L2 캐시
								 L3 캐시
								 주 메모리
slow & cheap		 대량 저장 장치
```

더 복잡한 수정을 가하면 성능을 더 향상할 수 있다. 기계에는 올바른 데이터를 메모리에서 프리페치(prefetch : 미리 페치해서 가져옴)해서 캐시를 준비시키기 위해 조건 분기 명령어의 결과를 예측하는 분기 예측(branch prediction)회로가 포함된다. 심지어 순서를 벗어나는 실행(out of order execetion)을 처리하는 회로도 존재한다. 이 회로는 CPU가 프로그램에 명시된 명령어 순서를 벗어나서 가장 효율적으로 명령어를 수행하게 해준다.

캐시 일관성(cache coherency)을 유지하는 것은 아주 어려운 문제다. 프로세서 칩이 2개인 컴퓨터는 각 코어가 4개 존재한다. 코어 중 하나는 데이터를 어떤 메모리 위치에 기록한다. 물론 실제에서는 캐시에 데이터가 먼저 기록되며 결국에는 메모리에도 기록된다. 이 데이터를 사용해야 하는 다른 코어나 프로세서가 해당 메모리 위치의 데이터가 변경됐음을 어떻게 알 수 있을까? 가장 간단한 접근 방법은 라이트 스루(write through)이다. 이 방법은 데이터를 캐시에 기록하는 동시에 메모리에도 기록한다. 하지만 이 방식은 캐시를 사용하는 장점 대부분을 없애버린다. 따라서 이런 문제를 해결하기 위해 다양한 추가 캐시 관리 하드웨어가 생겨났다.





### 코프로세서

프로세서 코어는 아주 복잡한 회로로 이뤄졌다. 몇 가지 연산을 코프로세서(coprocessor)라는 더 단순한 회로에 위임하면 프로세서 코어가 일반적인 연산에 활용할 수 있는 공간을 더 확보할 수 있다. 과거에는 한 칩 안에 모든 연산 회로를 넣기 어려웟기 때문에 코프로세서가 쓰였다. 예를 들어 프로세서 자체에 부동소수점 수 연산을 처리할 회로를 만들 공간이 없어서 부동소수점 연산용 코프로세서를 사용하는 경우가 있었다. 요즘은 그래픽 처리 등 여러 가지 기능을 담당하는 코프로세서가 한 칩에 같이 들어가 있는 경우가 많다.

이번 장에서는 프로그램을 실행하기 위해 메모리를 읽어 들이는 방법을 살펴봤다. 이 말은 프로그램이 디스크 드라이브 등의 더 느리고 값싼 메모리에 들어 있고 이를 불러 온다는 뜻이다. 그리고 가상 메모리 시스템이 스와핑을 하면서 디스크에 메모리 내용을 저장하거나 디스크에서 메모리로 데이터나 프로그램을 읽어온다는 사실도 살펴봤다. 그리고 디스크는 바이트 단위로 접근이 불가능하다는 사실을 봤다.(512 바이트나 4096 바이트 같은 블록 단위로 전송) 이 말은 주 메모리와 디스크 사이에 단순한(값을 복사만 하면 됨 연산은 필요없음) 데이터 복사가 자주 일어날 수 있다는 뜻이다. 일부 코프로세서는 다른 일은 처리하지 않고 데이터 복사만 담당한다. 이런 방식을 직접 메모리 접근(DMA : Direct Memory Access)라고 한다. 얼마만큼의 데이터를 복사하고 다른 곳에 알려주는 방식으로 DMA를 설정할 수 있다. CPU는 DMA에 일을 많이 떠맡기기 때문에 융요한 연샂ㄴ을 더 많이 처리할 수 있다.





### 메모리 상의 데이터 배치

이전의 과정을 통해 메모리에 명령어만 담는 게 아니라 데이터도 담는다는 사실을 알았다. 이 경우 데이터는 정적(static) 데이터이다. '정적'이라는 말은 프로그램을 작성할 때 얼마나 많은 메모리가 필요한 지 알고 있다는 뜻이다. 이번 장에서 앞부분에서 프로그램을 실행할 때 스택을 위한 메모리가 필요하다는 사실도 배웠다. 따라서 이런 여러 데이터 영역을 서로 충돌하지 않게 배치할 수 있어야 한다. 

MMU가 없을 대 폰 노이만 구조와 하버드 구조의 전형적인 메모리 배치를 보여준다. 유일한 차이는 하버드 구조에서는 명령어가 별도의 메모리에 존재한다는 점 뿐이다.

```
폰 노이만           하버드
스택                스택
|                   |
정적 데이터          정적 데이터
명령어					     
										명령어
```

프로그램이 메모리를 사용하는 방법이 한 가지 더 있다. 대부분의 프로그램은 동적(dynamic) 데이터를 다뤄야 한다. 동적 데이터는 프로그램을 실행하기 전에는 크기를 알 수 없는 데이터를 말한다. 예를 들어 메시징 시스템은 저장해야할 메시지 개수나 각 메시지 크기를 미리 알 수 없다. 이를 힙(heap)이라고 부른다. 더 많은 데이터를 저장해야할 경우 스택은 아래로 자라나는 반면, 힙은 위로 자라난다. 힙과 스택이 서로 충돌하지 않게 하는 것이 중요하다. 메모리 배치에는 몇 가지 사소한 변형이 있다. 예를 들어 일부 프로세서에는 메모리의 시작 부분이나 끝 부분에 인터럽트 벡터를 저장하는 영역이나 온칩 I/O 장치를 제어하기 위한 레지스터를 (메모리 주소를 사용해 접근할 수 있게) 확보해두기도 한다.

```
힙이 있는 경우의 메모리 배치

스택
\/
/\
힙
정적 데이터
명령어
```

마이크로컴퓨터에서는 MMU가 없는 경우가 많아 이런 메모리 배치를 자주 볼 수 있다. MMU가 쓰이는 경우에는 명령, 데이터, 스택이 각기 다른 물리적 메모리 페이지에 매핑되고, 필요에 따라 할당된 크기를 변경할 수 있다. 하지만 프로그램이 바라보는 메모리는 여전히 앞에서 설명한 것과 같은 메모리 배치를 사용한다.





### 프로그램 실행

컴퓨터 프로그램은 여러 부분으로 이뤄졌음을 살펴봤다. 여기서는 여러 부분이 어떻게 함께 사용되는지 살펴본다.

앞에서 프로그래머가 함수를 사용해 코드를 재사용한다고 설명했다. 이 설명이 전부가 아니다. 어떤 함수는 여러 프로그램에서 쓸만큼 유용한 경우도 있다. 예를 들어 두 문자열이 같은지 비교하는 함수가 필요한 프로그램은 아주 많다. 이런 편의를 달성하는 한 가지 방법은 관련 함수를 한데 모아서 라이브러리(library)를 만드는 것이다. 문자열 처리부터 복잡한 수학 계산이나 MP3 인코딩에 이르는 다양한 라이브러리가 존재한다.

본격적인 프로그램은 라이브러리 뿐이 아니라 여러 조각으로 이뤄진다. 프로그램 전부를 한 파일에 저장할 수도 있지만 이를 여러 파일로 나눠 놓는 편이 더 좋은 이유가 있다. 가장 큰 장점은 여러 사람이 한 프로그램의 여러 부분을 동시에 개발할 수 있다는 점이다.

하지만 프로그램을 여러 조각으로 나누면 이 모든 조각을 하나로 엮거나 연결(이를 link라고 한다.)할 방법이 필요하다. 각 프로그램을 링크하기 편한 형식의 매개 파일(intermediate file)로 나누고 링커(linker)라는 특별한 프로그램을 사용해 여러 조각을 하나로 연결해 실행한다. 과거 다양한 매개 파일 형식이 생겨났다. 실행과 링크가 가능한 형식(ELF : Executable and Linkable Format)은 현재 가장 유명한 매개 파일 형식이다. 이 형식은 마치 교차로 광고와 비슷한 여러 섹션(section)으로 이뤄진다. '팝니다' 섹션에는 나는 'cube 함수를 제공합니다.'라는 광고가 있다. 비슷하게 '삽니다' 섹션에는 '나는 date라는 변수를 찾습니다.'라는 광고가 있다.

링커는 이런 모든 광고를 서로 해소(resolve)해서 실제로 실행할 수 있는 프로그램을 만들어내는 프로그램이다. 물론 성능을 높이기 위해 훨씬더 복잡한 방식을 사용한다. 과거에는 라이브러리를 단지 함수가 들어있는 파일로 간주해서 프로그램의 나머지 부분과 직ㅈ버 연결해 실행 파일을 만들었다. 이런 방식을 정적 링크(static linking)라고 한다. 하지만 1960년대 멀틱스(Multics) 운영체제를 만든 프로그래머들은 여러 프로그램이 똑같은 라이브러리를 사용하는 경우가 많다는 사실을 발견했다. 라이브러리가 여러 프로그램에 쓰인다는 말은 이 라이브러리가 아주 쓸모 있다는 뜻이지만 정적 링크를 사용하면 같은 라이브러리 코드가 여러 실행 파일에 반복적으로 들어가서 귀중한 메모리를 낭비한다. 멀틱스 프로그래머들은 공유 라이브러리(shared library)를 사용하는 동적 링크(dynamic linking)을 발명했다. 다음 처럼 MMU가 여러 프로그램이 같은 라이브러리를 공유할 수 있게 해준다.

```
프로그램 a 물리 메모리 프로그램 2
  1  --  라이브러리 -- 2
```

공유 라이브러리에서 가져온 명령어는 이 라이브러리를 사용하는 모든 프로그램에서 공통적이라는 사실에 유의하라. 이로 인해 라이브러리 함수를 작성할 때 호출하는 프로그램의 스택과 힙을 사용하도록 함수를 설계해야만 한다. 

프로그램에는 진입점(entry point)이 있다. 진입점은 프로그램의 첫 번째 명령어가 위치한 주소를 뜻한다. 하지만 우리의 직관과 달리 실제 프로그램이 실행될 때 가장 먼저 실행되는 명령어는 진입점에 있는 명령어가 아니다. 프로그램을 이루는 모든 부분이 하나로 합쳐져서 실행파일(executable)을 이룰 때 런타임 라이브러리(runtime library)가 추가된다. 실제로는 런타임 라이브러리에 있는 명령어가 먼저 실행되고 나중에 진입점의 명령어가 실행된다.

런타임 라이브러리는 메모리 설정을 책입니다. 이 말은 런타임 라이브러리가 스택과 힙 영역을 설정한다는 뜻이다. 런타임 라이브러리는 정적 데이터에 위치한 데이터의 초깃값도 설정한다. 이런 값들은 실행 파일에 들어 있고 시스템에서 메모리를 할당받은 직후 실행 파일에서 메모리로 복사돼야 한다.

런타임 라이브러리는 더 많은 기능을 수행한다. 특히 언어가 복잡해지면 런타임 라이브러리의 기능도 더 복잡해진다. 다행히 현재로서는 이에 대해 알 필요가 없다.





### 메모리 전력 소비

지금까지는 성능 측면에서 메모리에 접근했다. 하지만 다른 점도 고려해야 한다. 데이터를 메모리에서 이리저리 옮기려면 전력(power)가 소비된다. 데스크톱 컴퓨터에서는 이런 전력 소비가 아주 중요한 일은 아니지만 모바일 장치에서는 전력 소비가 더 중요하다. 게다가 대형 인터넷 회사의 데이터 센터에서는 배터리 수명등이 문제가 되지는 않지만 컴퓨터가 아주 많기 때문에 적은 전력량이 합쳐져서 큰 값이 될 수 있다. 전력 소비와 성능 사이의 균형을 잡는 일은 아주 어렵다. 코드를 작성할 때도 이를 염두에 둬야 한다.





### 정리

메모리를 다루는 것이 그리 단순하지 않았다. 간단한 프로세서라도 메모리 사용을 개선하는 일은 아주 복잡하다. 이제 남은것은 I/O인데 이는 6장에서 다룬다.













 







