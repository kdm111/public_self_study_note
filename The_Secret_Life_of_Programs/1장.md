# 1. 컴퓨터 내부의 언어 체계



### 비트

비트는 binary와 digit가 합쳐진 말이다. 비트는 2진법을 사용한다. 



### 논리 연산

비트의 사용법중 하나는 boolean 질문에 대해서 true/false로 대답하는 것이다. 다른 비트들이 표현하는 내용으로부터 새로운 비트를 만들어내는 이 동작을 논리연산 (logic operation이라고 한다.



*불리언 대수*

대수가 수에 대한 연산 규칙의 집합인 것처럼 1800년대 조지 불이 만든 불리언 대수(Boolean Algebra)역시 비트에 대해 사용할 수 잇는 연산 규칙의 집합이다.

not : 논리적 반대

and : 곱연산

or : 합연산

xor : 배타적 or연산 (= (a or b) and (not(a and b)))



*드모르간의 법칙*

1800년대 영국 수학자 드모르간은 불리언 대수에 적용할 수 있는 법칙을 알아냈다. 

a and b = not(not a or not b)

a or b = not(not a and not b)

이 법칙을 이용하면 not을 충분히 사용하면 or만으로 and연산을 대신할 수 있고 and 연산만을 이용하면 or연산을 대신할 수 있다.

A or B = R ((notA and notB) = notR)

```
A | B  R    notA & notB notR   R 
F   F  F      T     T    T    F
F   T  T      T     F    F    T
T   F  T      F     T    F    T
T   T  T      F     F    F    T
```

위의 표에서는 or연산을 대신하여 not, and만으로 같은 결정을 내렸다. 이런 논리도 제대로 작동하지만 not연산을 수행하는 하드웨어에 돈이 들기도 하고 연산을 연쇄적으로 사용하면 계산이 느려진다.



### 정수를 비트로 표현하는 방법



*양의 정수 표현*

1우리는 10진수(decimal number)를 사용하는데 각 자리수는 밑이 10(base-10)인 시스템이라고 부른다.

비트를 사용해 값을 만들 때도 이와 비슷하게 접근할 수 있다. 사용할 수 있는 기호는 1과 0밖에 없다. 2진수 체계는 2를 밑으로 하는 수 체계이다. 

2진수로 4개의 비트는 0~15를 표현할 수 있다.

2진수에서 가장 오른쪽의 비트를 가장 작은 유효 비트 (least significant bit)라고 부르고 가장 왼쪽의 비트를 가장 큰 유효 비트(most significatn bit)라고 부른다. LSB를 건드리면 가장 작게 값이 바뀌고 MSB를 건드리면 값이 가장 크게 바뀐다.(컴퓨터를 사용하는 사람들은 종종 세 글자 줄임말 (TLA : three letter acronym))을 사용한다.

5028을 표현하려면 13비트가 필요한데, 가장 왼쪽에 있는 비트보다 더 왼쪽에 0을 추가하면 (이런 식으로 추가된 0들을 리딩 제로(leading zero)라고 한다.) 숫자를 표현하는 데 필요한 최소한의 비트보다 더 많은 비트를 추가할 수 있다. 컴퓨터는 미리 정해진 수의 비트를 한 덩어리로 사용하도록 되어있기 때문에2진수를 쓸 때는 항상 일정한 비트를 사용해 값을 표현하는 경우가 있다.

예시 ) 16비트 : 0000 0000 0000 0001



*2진수 덧셈*

2진수를 더할 때에는 각각 lsb부터 더하기 시작한다. 각각의 비트를 더한 결과는 두 비트의 xor연산과 같고 올림은 두 비트의 and연산과 같다. 

덧셈 결과가 우리가 사용할 비트의 개수의 범위를 넘어서면 오버플로가 발생한다. 오버플로는 MSB에서 올림이 발생했다는 뜻으로 

```
 1001
+1000
10001
```

MSB의 왼쪽에는 더이상 사용할 수 있는 비트가 없기 때문에 결과는 다음과 같다.

```
 0001 
```

나중에 알게 되겠지만 컴퓨터에는 조건코드(상태코드) 레지스터 (condition code register)라는 것이 있어서 몇 가지 이상한 정보를 담아둔다. 이런 정보 중에서 오버플로 비트가 있고 이 비트에는 MSB에서 올라가는 올림값이 들어간다. 이 비트값을 확인하여 오버플로가 발생했는지 확인할 수 있다.

한 수를 다른 수에서 빼는 것은 음수를 더하는 것과 마찬가지이다. MSB 위쪽에서 1을 빌려오는 경우를 언더플로라고 한다. 물론 이 조건코드 역시 컴퓨터에 들어있다.



*음수 표현*

4비트를 통해서는 0~15까지 16가지의 수를 표현할 수 있다. 하지만 꼭 4비트로는 0부터 15까지만 표현한다는 뜻은 아니다.



| 부호와 크기

음수와 양수를 구분하기 위해 양부호(+), 음부호(-)가 있는 것처럼 우리는 MSB를 부호에 사용하기로 결정했다. 따라서 4비트의 경우 3비트가 남고 0부터 7까지의 숫자를 표현할  수 있다. 부호가 0이면 숫자를 양수로 표현하고 1이면 숫자를 음수라고 하자. 그렇다면 15가지의 음수와 양수를 표현할 수 있다. 수의 범위는 -7~+7 총 15가지가 된다.

한 비트를 부호에 사용하고 나머지 비트를 수의 크기(절대값)을 표현하기위해 사용하는 방법을 부호와 크기(sign and magnitude)표현법이라고 말한다.

하지만 현재 부호와 크기 표현법은 0을 표현하는 방법이 두 가지라서 비용이 낭비되고, xor과 and를 통한 덧셈을 사용할 수 없게되어 널리 쓰이지 않는다.

양의 1과 음의 1을 더해보자.

```
  0001
+ 1001
  1010
```

음수 2라는 결과가 나오게 된다. 좀 더 복잡한로직을 사용하면 연산이 제대로 작동하게 할 수 있다. 하지만 더 나은 접근 방법이 제시된다.



| 1의 보수

음수를 표현하는 또 다른 방법은 양수의 모든 비트를 뒤집는 방법이 있다. 이 방법을 1의 보수(one's complement) 표현법이라고 부른다. 1의 보수 표현법에서도 부호와 크기 표현법과 비슷하게 부호비트와 나머지로 나눈다. 1의 보수에서는 not 연산을 통해 보수를 얻는다. 

```
0 0 0 1 +1
0 0 0 0 +0
1 1 1 1 -0
1 1 1 0 -1
```

1의 보수 표현법에는 0을 두가지로 표현한다는 문제가 존재한다. 게다가 1의 보수에서는 덧셈을 쉽게 할 수 없다. MSB쪽에서 올림이 발생한 경우 LSB로 올림을 전달해야 한다. 이를 순환올림(end-around carry)라고 한다.

```
  0 0 1 0
+ 1 1 1 0
1 0 0 0 0
  0 0 0 1
```

1의 보수를 사용하여 +2와 -1을 더하려면 일반 적인 양수 덧셈처럼 한 뒤 순환올림을 사용하면 된다. 이 방식은 잘 작동하지만 순환올림을 처리하기 위한 하드웨어를 추가해야 하기 때문에 좋은 해법은 아니다. 현대 컴퓨터에서는 부호와 크기나 1의 보수 둘 다 사용하지 않는다. 두 방식은 추가적인 하드웨어 없이는 작동할 수 없고 하드웨어를 추가한다는 말은 비용이 추가로 더 든다는 이야기 이다. 



| 2의 보수

특별한 하드웨어 추가 없이 xor연산과 and연산만 사용하여 정수사이 덧셈을 해보자. +1을 더했을 때 0이 나오는 비트패턴을 찾고 이 패턴을 -1이라고 불러보자. 4비트의 경우 +1은 0001이다. 1111을 0001에 더하면 0000이 나온다. 따라서 앞으로 1111을 4비트에서 -1을 표현하는 비트 패턴으로 사용하자.

이런 표현법을 2의 보수(two's complement)표현법이라고 하며 이 방법은 부호가 있는 정수를 표현할 때 널리 쓰이는 방법이다. 어떤 수의 not을 취하고 1을 추가하면 음수를 얻을 수 있다. 이때 올림이 발생하면 그 값은 버린다. 즉 4비트에서 1111은 -1을 표현하고 1101은 -2를 표현한다. 

프로그래머들은 자신이 다뤄야 하는 수를 표현하기 위해 필요한 비트의 개수를 알 필요가 있다.  프로그래머들은 본능처럼 이런 계산을 수행한다.

```
4비트 : -8~7
8비트 : -128~127
32비트 : -2,147,483,648 ~ 2,137,483,647
64비트 : ~900경~900경
```

비트가 커질 수록 표현할 수 있는 표현할 수 있는 숫자는 지수적으로 증가한다.  우리가 같은 숫자로 이뤄진 수를 보더라도 문맥에 따라 표현하는 값이 달라질 수 있다. 1111은 2의 보수에서는 -1이지만 부호와 크기에서는 -7이고 1의 보수에서는 -0이다.





### 실수를 표현하는 방법

지금까지 정수를 2진수로 표현하는 방법을 배워보았다. 그렇다면 실수는 어떻게 표현할 수 있을 까? 밑이 10인 실수에는 10진 소수점이 포함된다. 밑이 2인경우 실수를 표기하기 위해 2진 소수점을 표현할 방법이 필요하다. 여기서도 정수의 경우와 마찬가지로 문맥에 따라 실수를 표현하는 방법이 달라질 수 있다.



*고정소수점 표현법*

2진수를 사용해 소수를. 표현하기 위해 2진 소수점의 위치를 임의로 정하는 방법이 있다. 4비트가 있다면 그 중 2비트는 분수를 표현하는 데 사용할 수 있고 나머지로는 정수값을 표현하는 데 사용할 수 있다. 소수점의 위치가 항상 일정하기 때문에 이를 고정소수점(fixed-point)표현법이라고 부른다.

```
0 0 0 0 : 0 0 0.5 0.25
```

소수점의 왼쪽은 앞에서 본 2진 표현법과 비슷하다. 정수와 비슷하게 소수점 왼쪽의 2비트는 4가지 정수를 표현한다. 2진 소수점 오른쪽의 숫자들은 10진 소수점 오른쪽에 있는 숫자들과 비슷하게 분수를 표현한다. 다만 2 진수의 경우 0, 0.5, 0.25 등 2의 거듭 제곱을 사용한다.

이런 접근법은 잘 작동하지만 필요한 비트의 개수가 너무 많기 때문에 범용 컴퓨터에서 이런 방식은 사용하지 않는다. 특수한 일부 컴퓨터의 경우 그리고 나중에 배우겠지만 고정 소수점 수가 응용하기도 유용한 경우가 있다.

범용 컴퓨터는 일반적인 문제를 해결하기 위해 만들어진 컴퓨터 이기 때문에 그렇다. 일반적인 문제를 해결하기 위해서는 넓은 범위의 수를 다룰 수 있어야 한다. 플랑크 상수의 경우 6.63 * 10<sup>-34</sup>J/s라는 아주 작은 값이지만 아보가드로 수는 6.02*10<sup>23</sup>이라는 큰 수이다. 두  수는 2<sup>191</sup>의 차이를 가지고 있다. 거의 200비트의 차이를 가지기 때문에 많은 비트가 필요하므로 모든 수를 비트로 표현하면 메모리가 너무 많이 필요하기 때문에 다른 방법을 써야 한다.



*부동소수점 표현법*

플랑크 상수부터 아보가드로 수까지 범위의 값을 2진수로 표현한다는 문제를 해결하기 위해 과학적 표기법(scientific notation)을 2진수에 적용한다. 과학적 표기법은 수를 해석하는 새로운 방법을 도입해서 큰 범위의 수를 표현하다. 과학적 표기법에서는 10진 소수점 왼쪽이 한 자리뿐인 소수(가수)라고 한다. 10을 몇 번(지수) 거듭제곱한 값을 곱하는 방식으로 소수를 표현한다. 과학적 표기법에서는 0.12이 1.2*10<sup>-2</sup>라고 한다. 2진법으로 표기할 때는 10이 아닌 2를 밑으로 한다는 점만 다를 뿐이다. 따라서 가수 부분은 2진 소수, 지수 부분은 2의 거듭제곱 횟수를 표현한다.

이런 표현법을 부동 소수점(floating point)표현법이라고 부르는 이유가 헷갈릴 수 있다. 단순히 가수 부분만 보면 항상 2진 소수점의 위치가 같아 보이기 때문이다. 하지만 가수가 1.2로 항상 같다고 해도 지수가 무엇인가에 따라 소수점 왼쪽 자리가 1/10일 수도 있고 1일 수도 있고 1일 수도 있고 100,000일 수도 있다는 점을 생각하면 소수점 위치는 정해져 있지 않다고 말할 수 있다. 반면 고정 소수점의 경우 12.00, 1.2, 0.12로 고정소수점의 경우 소수점 바로 왼쪽에 있는 숫자는 항상 1의 자리를 말한다. 

여기서 지수의 밑인 2라는 숫자를 비트로 표현할 필요는 없다는 사실에 유의하라. 부동소수점 수의 정의상 밑 2는 항상 정의되어 있다. 부동소수점 표현법은 지수와 가수를 분리함으로써 수를 표현할 때 필요한 수를 표현할 때 필요한 0을 모두 저장하지 않고도 큰 수나 작은 수를 표현할 수 있다.

```
 가수  지수   값
  00.  00   0 (0.0 * 1)
  00.  01   0 (0.0 * 2)
  00.  10   0 (0.0 * 4)
  00.  11   0 (0.0 * 8)
  01.  00 0.5 (0.5 * 1)
  01.  01 1.0 (0.5 * 2)
  01.  10 2.0 (0.5 * 4)
  01.  11 4.0 (0.5 * 8)
  10.  00 1.0 (1.0 * 1)
  10.  01 2.0 (1.0 * 2)
  10.  10 4.0 (1.0 * 4)
  10.  11 8.0 (1.0 * 8)
  11.  00 1.5 (1.5 * 1)
  11.  01 3.0 (1.5 * 2)
  11.  10 6.0 (1.5 * 4)
  11.  11 12.0 (1.5 * 8)
```

이 표는 4비트만 사용하지만 부동소수점 표현법의 비효율성을 보여준다. 첫번째 비트 조합 중에 낭비되는 부분이 많다. 0을 표현하는 방법이 4가지나 된다. 둘 째 비트 패턴이 가능한 모든 수를 표현하지 못한다. 지수가 커질수록 가수의 한 패턴과 다른 패턴 사이의 값 차이가 커진다. 이로 인해 0.5와 0.5를 얻으면 1.0을 얻을 수는 있지만 6.5를 표현하는 비트 패턴이 없기 때문에 0.5와 6.0을 더할 수는 없다.(이 문제를 해결하기 위해 수치해석이라는 수학 분야가 있다.)



*IEEE 부동소수점 수 표준*

이상하지만 부동 소수점 수 시스템은 컴퓨터에서 계산을 수행할 때 실수를 사용하는 표준 방법이다. 더 많은 비트를 사용하며, 가수와 지수에 대해 각각 부호 비트를 사용한다. 다만 지수에 대한 부호 비트는 지수의 비트 패턴에 감춰져 있다. 그리고 낭비되는 비트 조합을 최소화하고 반올림을 쉽게 하기 위한 트릭이 사용된다.

똑같은 비트를 사용하더라도 정밀도(precision)를 가능한 높이고 싶다. 한 가지 트릭은 정규화(nomalization)이다. 정규화는 가수를 조정해서 맨 앞에 0이 없게 만드는 것이다. 이런 식으로 가수를 조정하면 지수도 조정해야 한다. 두 번째 트릭은 디지털 이큅먼트(DEC)사에서 고안한 것으로 가수의 맨 왼쪽 비트가 1이라는 사실을 알고 있으므로 이를 생략하는 것이다. 이로 인해 가수에 1비트를 더 사용할 수 있다.

IEEE 754의 세부사항을 모두 알 필요는 없다. 하지만 두 가지 부동소수점 수가 자주 사용된다는 사실은 알고 있어야 한다.  한 가지는 기본 정밀도(single precision) 부동 소수점 수이고, 다른 한 가지는 2배 정밀도(double precision) 부동소수점 수이다. 기본 정미롣 수는 32비트를 사용하며 7비트 정밀도로 +-10<sup>38</sup> 정도의 범위를 표현할 수 있다. 2배 정밀도 수는 64비트를 사용하기 때문에 더 넓은 범위를 표현할 수 있으며 +-10<sup>308</sup>범위의 수를 15비트 정밀도로 표현할 수 있다.

```
기본 정밀도 1+8+23 (부호+지수+가수)
2배 정밀도 1+11+52 (부호+지수+가수)
```

두 형태 모두 가수에 대한 부호를 사용한다. 그림에서 2배 정밀도 수가 기본 정밀도 수보다 3비트 더 크다는 점을 볼 수 있다. 따라서 지수의 범위는 8배가 된다. 2배 정밀도 수는 기본정밀도보다 가수 부분이 29비트가 더 크다. 따라서 정밀도 역시 더 높다.

또한 지수에 대해 따로 부호비트가 존재하지 않는데, IEEE 754를 설계한 사람들은 지수 비트가 모두 0이거나 1인 경우에 특별한 의미를 갖게 하고 실제 지숫값은 나머지 비트 패턴에 집어넣고 싶었다. IEEE 754 설계자들은 편향된(biased) 지숫값을 사용해 이를 달성할 수 있었다. 기본 정밀도의 경우 편향된 값은 127로 이 말은 127(01111111)이 지수 0을 표현한다는 뜻이다. 2진수 1을 표현하는 비트 패턴(00000001)은 지수에서는 -126을 표현하며, 2진수 254(11111110)는 +127을 표현한다. 2배 정밀도 수는 편향값으로 1023을 사용한다.

IEEE 754에서 편리한 점은 0으로 나눴을 때 생길 수 있는 양의 무한대나 음의 무한대를 표현하는 비트 패턴 등 여러 가지 특별한 비트 패턴을 제공한다는 점이다. 이런 비트 패턴 중에는 NaN(not a number)를 표현하는 특별한 값도 있다. 이로 인해 부동소수점 수로 계산을 하던 도중에 NaN 값이 생기면 뭔가 잘못된 산술 연산을 수행했다는 뜻이다. 이런 특별한 비트 패턴들은 앞에서 이야기한 특별한 지숫값을 사용한다.





### 2진 코드화한 10진수 시스템

방금까지 2진수로 수를 표현하는 일반적인 방식을 살펴봤다. 그 외에 2진 코드화한 10진수(BCD:Binary coded decimal)가 있다. BCD는 4비트를 사용해 10진 숫자를 하나 표현한다. 예를 들어 12를 이진수로 표현하면 1100이지만 BCD로 표현하면 0001 0010이다. 여기서 0001은 십의 자리에 1 0010은 일의 자리에 2를 표현한다. 

오래된 컴퓨터들은 BCD 수를 처리하는 방법을 알 고 있다. 하지만 이런 시스템은 더 이상 서류에 남아 있지 않다. 하지만 컴퓨터와 상호작용하는 장치 중에서 디스플레이나 가속도 센서 등이 BCD를 사용하는 경우가 있다.

BCD의 인기가 줄어든 이유는 BCD가 2진수를 효율적으로 활용하지 못하기 때문이다. BCD가 일반적인 2진수에 비해 같은 수를 표현할 때 더 많은 비트를 사용한다는 점을 눈치챘을 것이다. 과거에 비해 비트가 더 저렴해 졌지만 16가지 조합 중에 여섯 가지를 버려도 될 만큼 저렴해지지 않았다.





### 2진수를 다루는 쉬운 방법

2진수를 더 쉽게 읽을 수 있는 방법 중 몇 가지를 살펴보자. 



*8진 표현법*

눈에 좋은 표현법 중 하나는 8진 표현법(octal representation)이다. 8진은 밑이 8이라는 뜻으로 2진수 비트들을 3개씩 그룹으로 묶는 아이디어 이다. 3비트는 0~7까지 8개의 숫자를 표현하고 있는데 이렇게 하면 긴 2진수 숫자도 쉽게 보일 수 있다.

```
111 111
  7   7 = (8*1)*7 + (8*0)+7
```



*16진 표현법*

요즘 날에는 16진 표현법(hexadecimal representation)이 사용된다. 그 이유는 요즘은 컴퓨터 내부가 8비트의 배수를 사용해 만들어지기 때문이다. 8의 배수는 4로 균일하게 나눠지지만 3으로는 균일하게 나눠지지 않는다.

2진수를 표현하려면 두 가지 숫자만 있으면 된다. 8진수의 경우에도 8가지의 숫자만 필요하다. 하지만 16진수의 경우 하나를 표현하려면 0~9까지 에서 a~f까지의 숫자를 사용한다. 그래서 2진수 숫자를 4개씩 잘라내어 16진수로 표현한다.

```
0000 : 0 ~ 1111 : f
```



*프로그래밍 언어의 진법 표기법*

컴퓨터에서 어떻게 진법을 표기할 수 있을까? 여러 프로그래밍 언어에서는 다음과 같은 표기법을 따른다.

0으로 시작하는 숫자는 8진 숫자이다. 017은 8진수 이며 값으로 15이다.

1부터 9로 시작하는 수는 10진수이다. 123은 123이다.

0x가 접두사로 붙는 숫자는 16진수 이다. 0x12f는 16진수 이며 303이다.

c++ 같은 언어에서는 0b라는 접두사를 사용해 2진수를 표현한다.





### 비트 그룹의 이름

컴퓨터를 설계하는 사람은 비용을 고려해 컴퓨터가 사용할 비트의 개수와 비트의 조직을 결정해야 한다. 수 표현과 마찬가지로 비트도 여러 방식의 개수와 조직에 대해 아이디어를 냈지만 일부만 살아남았다.

비트는 너무 작아 기본 단위로 사용하기는 유용성이 떨어진다. 따라서 비트는 좀더 큰 덩어리로 조직화해야 한다. 현재 세계적으로 8비트 덩어리가 기본단위로 사용되기 시작했고 이를 바이트(byte)라고 부른다. 다른 크기의 덩어리도 이름이 존재한다.

``` 
니블(nibble)  : 4
바이트(byte)   : 8
하프 워드(half word) : 16
롱 워드(long word) : 32
더블 워드(double word) : 64
```

하프 워드, 더블 워드 라는 말은 있는 데 왜 워드라는 단어를 쓰지 않을까?  워드(word)는 컴퓨터가 설계상 자연스럽게 사용할 수 있는 비트 묶음의 크기를 가리키는 말로 쓰인다. 자연스럽게 쓸 수 있다는 말은 컴퓨터가 빠르게 처리할 수 있는 가장 큰 덩어리를 말한다. c나 c++같은 언어에서 int라고 선언한 변수가 이런 자연스로운 크기의 2진수를 표현한다.

큰 수를 가리키기 위해 사용하는 표준은 킬로(kilo), 메가(mega) 등등이 존재한다. 컴퓨터 엔지니어는 이런 용어들을 빌려와서 의미를 약간 바꿔 밑이 10이 아니라 2인 값을 표현하게 했다. 그래서 킬로비트(kilobit)나 킬로바이트(kilobyte) 에서 킬로는 1000을 뜻하지 않고 밑이 이면서 1000에 가까운 1024 2<sup>10</sup>을 표현한다. 메가는 2<sup>20</sup>, 기가는 2<sup>30</sup>을 뜻한다.

하지만 때때로 이런 말이 밑이 10인 용어를 뜻할 때도 있다. 그래서 IEC 표준 접두사가 만들어졌다. KiB는 2<sup>10</sup>, MIB는 2<sup>20</sup>을 표현한다.





### 텍스트 표현

컴퓨터는 항상 비트를 다룬다는 사실과 함께 비트를 사용해 수와 같은 대상을 표현할 수 있다. 이제 키보드나 문자에 있는 기호를 표현하는 방법을 알아보자.



*아스키 코드*

1963년부터 아스키는 키보드에 있는 모든 기호에 대해 7비트 수 값을 할당했다. 예를 들어 65는 알파벳 A를 66은 알파벳 B를 나타낸다.

아스키 코드 표는 또한 글자를 출력하는 데 사용되지 않고 장치를 제어하기 위해 사용되는 제어문자가 존재한다. null, cr, del 등등

이 중 상당수는 통신 제어를 위한 문자이다 예를 들어 ACK는 메시지를 받았음. 이고 NAK는 메시지를 받지 못함 이였다.



*다른 표준의 진화*

아스키는 영어를 표현하는 데 필요한 모든 문자를 포함하고 있어서 상당 기간 표준 역할을 했다. 초기 컴퓨터는 대부분 미국산이였고 미국산인 아닌 컴퓨터는 영국산이였다. 컴퓨터가 널리 보급됨에 따라 영어 외의 언어를 지원해야 할 필요가 늘어났다. ISO-646는 기본적으로 아스키를 확장해 액센트나 그 밖에 발음 기호를 추가한 것이다. 그리고 중국어, 아랍어, 한국어 등이 생겨났다.

각기 다른 표준이 존재하는 이유는 비트가 지금보다 더 비싼 시절에 표준이 만들어졌기 때문이다. 그래서 문자를 7비트나 8비트에 우겨넣었다. 비트 가격이 떨어짐에 따라 유니코드라는 새로운 표준이 만들어졌고 문자에 16비트 코드를 부여했다. 그 후 유니코드는 21비트까지 확장 되었으며 앞으로 모든 문자를 다 표현할 수 있을 것이다.



*유니코드 변환 형식 8비트*

컴퓨터는 7비트 값을 처리하지 않고 8비트를 사용해 아스키 문자를 저장한다. 이 경우도 과거에 비해 비트가 저렴해졌지만 8비트만 사용하면 모든 문자를 표현할 수 있는데도 굳이 16비트를 사용해 낭비해도 될 만큼 비트가 저렴하지 않아 한 문자를 8비트로 표현한다. 유니코드는 문자 코드에 따라 각기 다른 인코딩을 사용해 이런 문제를 해결한다. 인코딩(encoding)은 다른 비트 패턴을 표현하기 위해 사용하는 비트 패턴을 말한다. 우리는 비트와 같은 추상화를 사용해 숫자를 표현하고 숫자를 사용해 문자를 표현하고 다시 다른 숫자를 사용해 문자를 표현하는 숫자를 표현한다. 이 경우 미국 컴퓨터 과학자 켄 톰슨과 캐나다 프로그래머 롭 파이크가 만든 utf-8(unicode transromation format 8)이 하위 호완성과 효율성 때문에 많이 사용된다. utf-8은 모든 아스키 문자를 8비트로 표현하기 때문에 아스키 데이터를 인코딩 할 때는 추가 공간이 필요하지 않다. utf-8은 아스키가 아닌 문자의 경우 아스키를 받아서 처리하는 프로그램이 깨지지 않는 방법으로 문자를 인코딩한다.

utf-8은 문자를 8비트 덩어리(옥텟-octet)의 시퀀스로 인코딩한다. utf-8에서 교모한 부분은 첫번째 옥텟의 MSB 쪽에 있는 비트들이 옥텟 시퀀스의 길이를 표현하고(MSB 쪽의 비트 패턴이 겹치지 않아서) 옥텟의 맨 앞을 구별하기 쉽다는 데 있다. 프로그램이 문자 경계를 찾아야 하는 경우 이런 특성이 아주 유용하다. 모든 아스키 문자는 7비트에 들어가기 때문에 옥텟 하나만 사용해서 표현할 수 있다. 영어의 경우 비 아스키 코드를 사용하는 것보다 더 적은 용량으로 문자를 코딩할 수 있기 때문에 이런 특성이 아주 유리하다. 

다음은 utf-8이 어떻게 유니코드 문자를 인코딩 하는지 보여준다.

```
0000 0000 0010 0001 : 0x0041(유니코드 A)
          0010 0001 : 0x41(utf-8 A)
```

위에서 A라는 글자는 문자의 숫자 코드가 아스키와 유니코드에서 같다는 것을 알 수 있다. A를 utf-8로 인코딩 할 때 7비트 안에 문자의 코드가 범위에 들어가면 utf-8 인코딩에서는 옥텟을 하나만 사용하여 MSB에 0을 추가해 설정한다.

다음은 $\pi$에 대한 에 대한 유니코드변환이다.

```
0000 0011 1100 0000 : 0x03c0(유니코드 pi)
1100 1111 | 1100 0000 : 0xcf 0x80(utf-8 pi) 
```

이 값은 7비트에 들어가지 않지만 11비트로는 표현이 가능하다. $\pi$를 utf-8로 표현하기 위해서는 옥텟 2개를 사용하되 첫 번째 옥텟의 MSB 3비트를 110으로 시작하고 두번째 옥텟의 MSB 비트는 10으로 시작한다. 이렇게 하면 첫 번째에서 5비트 두 번째에서 6비트가 남아서 11비트 코드를 모두 담을 수 있다. 

다음은 검은 :four_leaf_clover: 심볼이다.

```
0010 0110 01100 0011 : 0x2663
111 00010 | 10 011001 | 10 100011 : 0xe2 0x99 0xa3
```

이 기호는 16비트에 들어가기 때문에 옥텟 3개를 사용해 표현한다.





### 문자를 사용한 수 표현

utf-8은 문자를 표현하는 비트들로부터 나온 숫자들(0x0000)을 표현하는 숫자들(utf 인코딩)을 표현하기 위해 숫자(utf-8 0x00)를 사용한다. 이제는 문자를 사용해 수를 표현할 수도 있다. 컴퓨터와 컴퓨터 사이에 통신이 시작한 이래로 사람들은 더 많은 정보를 컴퓨터 사이에 송수신하고 싶었다. 사람들은 2진수를 직접 보내고 싶었다. 2진 데이터를 직접 보내는 것은 생각처럼 단순하지 않았다. 아스키 코드의 상당수가 제어 문자로 예약되어 있었고, 이런 제어 문자는 시스템마다 처리하는 방식이 달랐다. 그리고 몇몇 시스템은 7비트만 송수신 할 수 있었다.



*출력 가능하게 변경한 인코딩*

출력 가능하게 변경한 인코딩(Queoted-printable encoding)은 QP 인코딩이라고도 하는데 8비트 데이터를 7비트 데이터만 지원하는 통신 경로를 통해 송수신 하기 위한 인코딩 방법이다. QP 인코딩은 전자우편 첨부를 처리하기 위해 만들었다. 이 인코딩을 사용하면 `=` 다음 각 바이트의 각 니블을 표현하는 16진 숫자 2개를 추가해 8비트값을 표현한다. 물론 이로인해 `=`가 특별한 이미지를 가지기 때문에 QP에서 =을 표현하려면 0x3D를 사용해야 한다. 

QP 인코딩은 몇 가지 추가 규칙을 사용한다. 줄 맨 끝에 탭과 공백 문자가온다면 각각 0x09 0x20으로 표현해야 한다. 인코딩된 데이터는 한 줄이 76자를 넘을 수 없다. 어떤 줄 의 맨 뒤가 `=`으로 끝나면 가짜 줄바꿈(한 줄의 길이는 76문자를 넘으면 안되므로 여러 줄로 나눠서 작성해야 하고 가짜 줄바꿈은 실제 원문의 줄바꿈이 아니므로 이를 표현하기 위해 =을 붙인다.)을 뜻하며 수신 쪽에서 QP로 인코딩 데이터를 디코딩할 때는 `=`을 제거하고 해석한다.



*베이스64 인코딩*

QP 인코딩이 잘 작동하기는 하지만 1바이트를 표현하기 위해 3바이트를 사용하기 때문에 매우 비효율적이다. 베이스64(base64) 인코딩이 더 효율적인데, 지금보다 컴퓨터 사이의 통신 속도 느렸던 시절헤는 이 효율성이 중요했다. 베이스 인코딩은 3바이트 데이터를 4문자로 표현한다. 3바이트 데이터의 24비트를 네 가지 6비트 덩어리로 나누고 각 덩어리의 6비트가뵷에 출력 가능한 문자를 할당해 표현한다.

```
숫자 : 문자
 0  :  A
 1  :  B
 2  :  C
 ...
52  :  0
53  :  1
54  :  2
63  :  /
```

0,1,2라는 세 바이트를 인코딩하면 AAEC이다. 다음은 이 변환 과정을 보여준다.

```
0000 0000 0000 0001 0000 0010
000000 000000 000100 000010 (0042)(AAEC)
```

이 인코딩은 모든 3바이트 조합을 4바이트 조합으로 변환할 수 있다. 하지만 원본 데이터 길이가 3바이트의 배수라는 보장이 없다. 따라서 패딩(padding) 문자를 도입해 이런 문제를 해결한다. 원본 데이터가 2바이트 남으면 `=`을 붙이고 1바이트가 남으면 `==`를 붙인다. 

이 인코딩 방식은 전자우편 첨부파일 전송에 많이 사용 중이다.



*URL 인코딩*

QP 인코딩에서 `=`에 특별한 기능이 있다는 것을 확인했다. 그래서 특별한 기능에 해당하지 않는 `=`를 표현하기 위한 다른 매커니즘을 도입한 것도 살펴봤다. 웹 페이지의 URL 표현에도 이와 같은 방식을 사용한다.

웹 페이지 URL에서 %26이나 %2F 같은 문자 시퀀스 를 본적이 있을 텐데 이런 값이 있는 이유는 URL이라는 문맥에서 몇몇 문자가 특별한 의미를 가지기 때문이다. 하지만 이런 특별한 의미를 지니는 문자를 리터럴(literal)로 사용할 필요가 있다.

문자들은 8비트 덩어리의 시퀀스로 표현된다. 각 덩어리는 2개의 16진 문자로 표현할 수 있다. URL 인코딩은 퍼센트 인코딩이라고도 부르는데, %뒤에 어떤 문자의 16진 표현을 덧 붙이는 방식으로 문자를 인코딩한다.

예를 들어 슬래시 문자(/)는 URL에서 특별한 의미를 가진다. 이문자는 47, 16진수로는 2F이다. `/`을 URL에 사용하되 `/`가 표현하는 특별한 의미를 사용하고 싶지 않을 때 %26이라는 문자열로 대신한다.(그리고 %역시 여기서 특별한 의미를 부여했기 때문에 %의 리터럴을 표현하기 위해서는 %25를 사용해야 한다.)





### 색을 표현하는 방법

숫자를 사용하는 일반적인 경우 중에 색 표현이 있다. 컴퓨터 그래픽스는 전자 모눈종이에 해당하는 것에 색을 표현하는 점(blob)을 찍어서 그림을 만드는 과정이다. 이때 모눈의 각 격자에 찍는 점을 찍어 그림을 만드는 과정이다. 각 격자에 찍는 점을 그림 원소(picture element)라고 부르고, 줄여서 픽셀(pixel)이라고 부르낟.

컴퓨터 모니터는 R,G,B 광선을 섞어서 색을 만들어내며 이런 색 표현법을 RGB 색 모델이라고 부른다. 색은 컬러큐브(color cube)라는 것으로 표현할 수 있다. 각 축은 primary 색을 표현하며 값이 0이면 그에 해당하는 주 색의 빛을 끈다는 의미이다. 값이 1이면 해당하는 주 색의 빛을 가능한 최대 밝기로 켠다는 의미이다. 

아무 빛이 없으면 검은색이고 모든 색을 최대로 키면 흰색이라는 사실을 볼 수 있다. 이런 식으로 빛을 혼합해 색을 표현하는 방식을 가산(additive) 색 시스템이라고 부른다. 각 빛을 섞을수록 더 밝은 색이 나온다.

손으로 그림을 그린다면 감산(subtractive) 색 시스템이 익숙할 것이다. 감산 색 시스템이서는 청록색(C), 자홍색(M), 노란색(Y)이다. 감산색 시스템은 흰색 광선에서 각 색의 파장을 제거하면서 색을 만들어내는 반면 가산 색 시스템은 특정 빛의 광선을 서로 추가해서 색을 만든다. 두 시스템 모두 눈이 볼 수 있는 모든 색을 만들어 낼 수는 없지만 가산 시스템이 감산 시스템보다 더 많은 색을 만들어낼 수 있다. 컴퓨터에서 작업하는 작업자들이 인쇄 됐을 때와 똑같은 모습을 화면에서 볼 수 있게 해주는 다양한 인쇄 전(prepress) 기술이 존재한다. 

눈은 천만가지 색을 구분할 수 있지만 이 구분은 선형적이지 않다. 빛의 세기를 2배로 하더라도 눈이 인식하는 밝기가 2배가 되지는 않는다. 더 큰 문제는 빛의 세기에 맞춰서 눈의 응답이 점차 변한다는 데 있다. 이를 암순응(dark adaptation)이라고 한다. 그리고 색이 다르면 눈의 반응도 다르다. 눈은 녹색의 변화에는 민감하지만 파란색의 변화에는 상대적으로 덜 민감하다. 미국 국가 텔레비전 시스템 위원회는 이런 현상을 활용했다. 현대 컴퓨터들은 색을 표현하는 데 24비트를 사용해 1천만에 가장 가까운 2의 제곱수에 해당하는 색을 표현할 수 있다. 24비트는 세 가지 8비트 필드로 나뉘며 각 필드는 세 가지 주요 색을 표현한다.

현대 컴퓨터들이 24비트 단위로 계산을 수행하지 않기 때문에 24비트에 가장 가까운 표준 크기인 32비트(롱 워드)에 색을 넣어서 처리하곤 한다.

```
0    7 8     15 16   23 24    31
 blue   green     red     미사용
```

색을 표현할 때마다 8비트가 손해본다는 사실을 알 수 있다. 800만개가 넘는 픽셀을 사용하는 요즘은 낭비되는 비트가 매우 많다는 것을 알 수 있다. 그래서 나머지 8비트를 투명도(transparency)에 사용한다.



*투명도 추가*

초기 애니메이션에서는 각 프레임을 손으로 직접 그렸다. 이는 매우 많은 노동력이 필요하고 각 프레임의 배경을 정확히 재생산할 방법이 업어 수많은 시각적 흔들림(jitter)이 존재했다. 이에 미국 애니메이터 존 브레이와 얼 허드는 1915년 셀 애니메이션(cell animation)을 발명해 해결했다. 셀 애니메이션에선느 움직이는 캐릭터를 투명한 셀룰로이드 필름 위에 그려서 정적인 배경 이미지 위에서 움직이게 만들었다.

컴퓨터 애니메이션은 1970년대와 80년대에서 널리 만들어지기 시작했다. 그 시절에서 감독이 원하는 모든 기능을 처리할 만큼 컴퓨터가 빠르지 못했다. 그래서 각기 알고리즘으로 만들어진 물건을 하나로 합칠 방법이 필요했다. 셀 애니메이션과 마찬가지로 투명도가 있으면 여러 이미지를 하나로 합성(compose)하거나 결합할 수 있다. 김프(GIMP)나 포토샵(Photoshop)을 다뤄본 사람이라면 이런 개념에 익숙할 것이다. 

1984년 루카스필름의 톰 더프와 토마스 포터는 투명도와 합성을 구현하는 새로운 방법을 발견했고 이 방법은 표준이 됐다. 이들은 각 픽셀에 알파($\alpha$)라는 투명도 값을 추가했고 $\alpha$는 수학적으로 0이상 1이하인 값이다. 0은 해당 값이 완전 투명한 값이라는 뜻이고 1은 완전히 불투명하다는 뜻이다. 여러 다른 알파값의 색을 합성해 새로운 색을 만들어내는 방법을 정의하는 일련의 합성 계산법(compositing algebra) 식이 있다.

더프와 포터의 구현은 기발했다. 그들은 부동소수점을 사용하지 않았기 때문에 1부터 255까지 값을 $\alpha$ 값으로 사용했고 위에서 사용하지 않았던 8비트를 사용했다. RGB 색을 그대로 저장하는 대신 더프와 포스터는 각각의 색값에 $\alpha$를 곱한 값을 저장했다. 예를들어 중간 정도의 밝기의 빨간색이라면 R=200, G=0, B=0이다. 이 색이 완전히 불투명 하다면 R=200 절반정도 투명하다면 R=200*0.5=100이고, 저장된 $\alpha$는 255\*0.5=127이다. 

```
0    7    8     15   16   23  24   31
 blue*a   green*a     red*a      a
```

따라서 이미지 합성은 색값을 $\alpha$로 곱하는 과정을  통해 이루어진다. 미리 곱한 값을 저장한다는 말은 픽셀을 사용할 때마다 $\alpha$를 곱하는 계산을 반복할 필요가 없다는 것이다.



*색 인코딩*

웹 페이지는 주로 사람이 읽을 수 있는 utf-8 문자의 시퀀스로 이뤄지는 텍스트를 표현하기 때문에 텍스트를 사용해 색을 표현할 방법이 필요하다.

URL 인코딩과 비슷한 방법을 색을 인코딩한다. 웹에서는 색을 16진 트리플렛(hex triplet)으로 표현한다. 16진 트리플렛은 #뒤에 여섯 자리 16진 숫자를 추가해 `#rrggbb`처럼 표현하는 방식이다. 예를 들어 노란색은 `#ffff00`, 검은색은 `#000000`, 흰색은  `#ffffff` 으로 표시된다. 각각의 8비트 색값을 두 자리 문자로 된 16진 표기로 바꾼다.

웹 페이지에서도 $\alpha$를 사용할 수 있지만 간결한 형식은 없다.  전혀 다른 방식을 사용한다.





### 정리

1장에서는 개념적으로 단순한 비트를 사용해 숫자, 문자, 색 등 복잡한 요소를 표현할 수 있다는 사실을 배웠다. 그리고 10진수를 2진수로 표현하는 방법과 2진수를 사용해 사칙연산을 수행하는 방법, 음수와 분수를 표현하는 방법도 배웠다. 그리고 비트를 사용해 문자를 인코딩 하는 표준을 배웠다.



