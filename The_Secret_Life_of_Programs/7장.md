# 7. 데이터 구조와 처리

> 어떻게 해야 프로그램에서 데이터를 잘 구성하고 처리할까

지금 까지 살펴본 바로는 메모리를 다룰 때마다 약간의 강박을 느꼈을 것이다. DRAM, 플래시 메모리, 디스크 드라이브 등의 메모리 장치를 읽고 쓰는 방식이 각 메모리 장치의 속도에 영향을 끼친다는 사실을 봤다. 5장에서는 데이터가 캐시 메모리에 있는지 여부에 따라 성능이 달라진다는 점도 살펴봤다. 이런 메모리 시스템의 특성을 염두에 두고 데이터를 조직적으로 잘 정리하면 더 나은 성능을 얻을 수 있다. 이번에는 데이터를 잘 정리하도록 데이터 구조(data structure) 즉 데이터를 조직화하는 표준적인 방법을 살펴본다. 데이터 구조 중 상당순느 여러 유형의 메모리를 효율적으로 사용하기 위해 존재한다. 어떤 연산을 더 빨리 작동하게 개선하려면 공간/시간 트레이드 오프가 발생하는 경우가 자주 있다.(하드웨어가 아니라 프로그래밍 언어가 고수준 데이터 구조를 제공한다.)

참조 지역성(locality of reference)이라는 말은 이번 장이 다루는 내용 중 상당수를 버즈워드(buzzword)와 비슷하게 요약해준다. 참조 지역성을 다른 말로 하면 '필요한 데이터를 메모리 서로 근처에 유지하라. 금방 사용할 데이터라면 더 가까운 곳에 저장하라'이다. 





### 기본 데이터 타입

프로그래밍 언어는 다양한 기본 데이터 타입(primitive data type)을 제공한다. 이런 타입에는 크기(비트 수)와 해석(부호가 있는지 없는 지, 부동소수점 수인지, 불리언인지)이라는 두 가지 측면이 존재한다. C언어 뿐만 아니라 파스칼, 자바 같은 언어는 물론이고 같은 기계에서 실행되는 다른 C언어 구현의 경우에도 이런 데이터 타입을 다른 방식으로 표현할 수 있다. 일부 언어 환경은 사용자가 엔디안(endianness), 바이트당 비트 수 등의 정보를 알아낼 수 있는 도구를 제공하기도 한다.

미국 엔지니어 해럴드 로슨은 1964년 PL/I(Programming language One)에서 포인터를 발명했다. 포인터(pointer)는 단지 컴퓨터 아키텍처에 따라 결정되는 크기의 부호가 없는 정수에 불과하며, 정숫값이 아니라 메모리 주소로 해석된다. 포인터는 집 주소와 비슷하다. 주소가 집 자체는 아니지만 집을 찾을 때 주소를 쓸 수 있는 것처럼 원하는 값이 있는 위치를 포인터로 알 수 있다. '주소 지정 모드'에서 간접 주소 지정이 바로 포인터다. 값이 0인 포인트, NULL은 제대로 된 주소로 인정하지 않는다.

포인터는 C가 인기를 끌면서 유명세를 탔다. 일부 언어는 잘못된 포인터 사용으로 인한 오류를 막기 위해 참조(reference 레퍼런스)라는 더 추상적인 개념을 구현하기도 한다. 참조에 대해서는 이번 장 뒷부분에서 다룬다. 포인터는 보통 한 사이클 안에 컴퓨터 내의 대상에 접근하기 위해 대상 컴퓨터에서 자연스러운 워크 크기와 같은 경우가 많다.

칩 기술의 발전으로 80년대 CPU가 많이 등장했고 특히 16비트에서 32비트 컴퓨터로 전환이 이뤄졌다. 특히 16비트에서 32비트 컴퓨터로 전환이 이뤄졌다. (물론 2020년 대부분이 64비트로 전환이 끝난 상태다.) 70년대나 80년대 초반 작성된 코드 중 상당수는 포인터를 무신경하게 사용했다. 예를 들어 포인터와 정수가 같은 크기라고 가정하고 둘을 서로 바꿔 쓰는 경우가 많았다. 새로 등장한 아키텍처로 이런 코드를 포팅하면 프로그램이 깨지고 종종 디버깅하기 어려운 방식으로 잘못되는 경우도 있다. 이런 문제를 해결하기 위해 이식성(portability)과 포인터를 아예 없앤 언어가 등장 하기도 했다.



### 배열

앞에서 본 데이터 구조는 주소와 값을 연관시킨 형태로 아주 단순했다. 프로그래밍 언어는 배열(array)를 지원한다. 배열은 마치 아파트와 같다. 아파트동에는 주소가 있고 한 아파트 동 안의 각 집에는 번호(호수)가 있다. 프로그래머는 호수를 인덱스(index)라고 부르고, 각각의 집을 원소(element)라고 부른다. 일반적인 컴퓨터 개발 규정(프로그래밍 언어의 문법)에서는 배열 원소의 타입이 모두 같아야 한다고 정해져 있다.

각 호수는 바이트다. 16비트 아이템이 모인 배열에서 각 원소는 8비트 바이트가 2개 들어가 있다. 원소의 첨자는 배열 인덱스를 말한다.

배열을 바라보는 다른 관점은 '상대 주소 지정'이라는 것을 통한 것이다. 각 원소는 0번째 원소의 주소인 기저 주소(base address)로부터 얼마나 멀리 떨어져 있는지를 나타내는 오프셋(offset)으로 지정할 수 있다. 따라서 원소1은 원소 0으로 부터 2바이트 떨어져 있다.

배열은 1차원(one-dimensional) 배열이다. 1차원 배열은 층마다 집이 하나 밖에 없는 아파트이다. 프로그래밍 언어는 다차원(multidimensional) 배열을 지원하기도 한다. 예를들어 아파트 동, 층, 호수를통해 3차원 배열을 만들 수 있다. 

다차원 배열은 어떻게 메모리에 저장될까 먼저 행 우선(row major)로 저장된 원소 배치를 보면 먼저 원소0을 방문해서 00,01을 순서대로 방문한 뒤 다른 원소로 가서 10, 11을 방문하게 된다. 이 방법은 지역성이 좋고 연산이 비교적 빠르다.

```
원소0 - 원소00 원소01
원소1 - 원소10 원소11
```

열 인덱스가 바뀌면 인접한 메모리 위치에 있는 원소로 이동하지만 행 인덱스가 바뀌면 인접한 행으로 이동해야 하기 때문에 연속적인 메모리 공간 상으로는 존재하는 열의 개수 만큼 이동하게 된다. 따라서 더 많은 이동이 일어난다.

만약 원소 10에 접근하려면 파스칼 같은 프로그래밍 언어에서는 배열 인덱스가 미리 정해둔 배열 인덱스 범위를 넘어서지 않는 지 검사한다. 하지만 인덱스 검사를 하지 않는 언어도 많다.(C or C++) 인덱스 검사가 없는 언어에서 원소 10을 접근하면 배열 시작 주소 기준으로 20번째와 21번째 바이트에 접근한다. 만약 이 주소에 아무 메모리가 없으면 프로그램이 망가지거나 배열을 벗어나는 위치에 있는 데이터에 접근할 수 있어서 보안상 구멍이 생길 수 있다. 언어가 인덱스 검사를 해주지 않는 다면 프로그래머가 주의해야 한다.



### 비트맵

기본 데이터 타입을 사용해 배열을 만드는 방법을 살펴봤다. 하지만 원하는 데이터를 표시하기에는 기본 데이터가 너무 클 때도 있다. 예를 들어 1비트만 사용하면 되는 프로그램에서 1바이트를 사용하게 된다면 100비트만 사용하면 되는 메모리에서 100바이트를 사용해야 할 수도 있다. 이 때 필요한 것이 비트맵이다.

비트맵을 만들기는 쉽다. 15비트를 추적할 때 2바이트가 2개 있으면 충분히 담을 수 있다.

```
비트들0  7  6  5  4  3  2 1 0
비트들1    14 13 12 11 10 9 8
```

비트맵에 대해 수행할 수 있는 기본 연산은 비트 설정하기(set), 비트 지우기(clear), 비트가 1인지 검사하기, 비트가 0인지 검사하기 네 가지 이다.

정수 나눗셈을 통해 특정 비트가 들어 있는 바이트를 찾을 수 있다. 필요한 연산은 8로 나누는 것 뿐이다. 배럴 시프터가 있으면 값을 3비트 오른쪽으로 시프트함으로써 빠르게 이를 계산할 수 있다. 예를 들어 비트가 17이라면 17/8은 나머지가 2이므로 두 번째 바이트에서 비트를 찾을 수 있다.

다음 단계로 비트 위치에 대한 마스크를 만들어야 한다. 물리적인 마스크와 마찬가지로 마스크는 들여다볼 수 있는 구멍이 있는 비트  패턴을 말한다.

배열 인덱스와 비트 마스크를 사용하면 다음 연산을 더 쉽게 할 수 있다. 

```
비트 설정하기 : 비트들 = 비트들 or 마스크
비트 지우기 : 비트들 = 비트들 and not 마스크
비트 1인지 검사 : 비트들 = (비트들 and 마스크) != 0
비트 0인지 검사 : 비트들 = (비트들 and 마스크) == 0
```

자원이 사용 가능하거나 사용 중인지 여부를 나타낼 때도 비트맵을 유용하게 사용할 수 있다. 사용 중인 자원을 비트로 표현하면 0이 하나라도 있는 바이트를 찾기 위해 배열을 검색할 수 있다. 일단 이런 바이트를 찾으면 한 번 더 1인 비트나 0인 비트를 찾아내야 하지만, 그렇더라도 각 비트를 하나씩 따로 검사하는 것보다는 훨씬 효율적이다.



### 문자열

여러 문자로 이뤄진 시퀀스를 문자열(string)이라고 한다.

배열과 마찬가지로 문자열을 연산할 때도 그 길이를 알아야 한다. 보통 각 문자열을 위해 배열을 할당하는 것만으로는 충분하지 않다. 그 이유는 길이가 변할 수 있는 가변 문자열 데이터에 작용하는 프로그램이 많지 않기 때문이다. 문자열 길이를 미리 알 수 없는 경우 큰 배열을 사용하는 경우가 많다. 하지만 배열 크기는 문자열 길이와 관계가 없기 때문에 문자열 길이를 추적할 방법이 필요하다. 가장 편한 방법은 문자열 데이터안에 문자열 길이를 어찌어찌 넣는 것이다.

한 가지 접근 방법은 문자열 안에 길이를 저장하는 것이다. 예를 들어 첫 번째 바이트에 문자열 길이를 넣을 수 있다. 이 방법은 잘 작동하지만 문자열의 길이가 255글자로 제한된다. 255글자는 여러 어플리케이션에서 충분하지 않다. 더 긴 문자열을 지원하기 위해 길이에 바이트를 더 할당할 수 있지만 어느 순간이 되면 부가 비용(길이를 위한 바이트 수)이 수많은 문자열 길이를 넘어 서는 경우가 생긴다. 그리고 문자열은 바이트라서 메모리 정렬(alignment)이 그때그때 다를 수 있다. 하지만 길이를 저장하기 위해 몇 바이트를 할당하는 경우 길이 정보는 반드시 올바른 메모리 정렬 경계에 있어야 한다.

C는 PDP-11 어셈블리 언어의 .ASCIZ 의사명령어(pseudo-instruction)에서 빌려온 다른 접근 방법을 사용한다. C는 다른 언어와 달리 문자열을 위한 전용 데이터 타입을 제공하지 않는다. 대신 1차원 바이트 배열을 사용한다. 문자열이 문자 배열이기 때문에 C에서 1바이트를 나타내는 데이터 이름이 char가 되었다. 하지만 C 문자열은 길이를 저장하지 않는 다는 점이 다르다. 대신에 문자 배열에 들어 있는 문자열 데이터의 끝에 바이트를 하나 추가하고 여기에 문자열의 끝을 표시하는 문자로 NUL을 넣는다. C는 아스키 문자, 즉 0을 문자열 터미네이터(string terminator)로 사용한다. 이 방법은 아스키와 UTF-8 문자열에서 모두 사용할 수 있다.

```
0 1 2 3 4 5
h e l l o \0
```

위를 보면 실제 문자의 길이는 5이지만 실제로는 6바이트를 사용한다. 문자열 터미네이터 때문이다.

대부분에 기계에는 주어진 값이 0인지 검사하는 명령어가 있기 때문에 NUL이 좋은 터미네이터 문자임이 드러났다. 다른 문자를 터미네이터로 쓰면 널 문자인지 검사하기 위해 그 값을 적재(load)해야 해서 비용이 더 들었을 것이다.

명시적으로 길이를 사용하지 않고 문자열 터미네이터를 사용하는 방식에는 장단점이 있다. 저장이 쉽다는 점은 아주 중요한 장점이고, 기본적으로 '문자열의 끝까지 각 문자를 출력하라'와 같은 일을 할 때 부가 비용이 들지 않는다는 점도 장점이다. 반면 문자열 길이를 알아내려면 문자열 터미네이터를 발견할 때까지 문자열을 스캔하면서 문자 수를 세야 한다는 단점이 있다. 그리고 문자열 중간에 NUL을 넣고 싶을 때는 이 방법을 사용할 수 없다.





### 복합 데이터 타입

현대적인 대부분의 언어는 원하는 대로 데이터 타입 즉 구조체(structure)를 만들 수 있는 방법을 제공한다. 구조체 안에 있는 여러 데이터를 구조체의 멤버(member)라고 한다.

일정관리 프로그램을 작성한다고 할 때 이벤트의 시작과 끝이 들어 있는 리스트가 필요하다. 이 프로그램을 c로 작성하려면 월,일,시,분,초 등은 1바이트로 충분하지만 연도의 경우 2바이트가 필요하다. 다음은 일시를 표현하는 구조체를 보여준다.

```
hours(1)-minites(1)-seconds(1)-year(2)-month(1)-day(1)
```

반드 시 이런 구조는 아니다. 하지만 일시를 표현하는 구조체의 배열이 있다면 분명 더 편하고 코드를 읽고 이해하기도 더 쉬울 것이다. 영국 피터 란딘(peter landin)은 1964년 이런 식으로 프로그램을 더 '달콤하게' 만들어 주는 비필수적 요소에 대해 편의 문법(syntatic sugar)라는 단어를 만들어 냈다. 

물론 어떤 사람에게 그냥 좀 편리하게 해주는 것에 불과한 요소가 다른 사람에게는 필수 기능일 수도 있다. `a = a + 1`이 `a++` 이나 `a += 1`으로 대신 하는 경우가 편의 문법이라고 주장하는 사람은 아주 많지만, 구조체의 배열을 배열의 집합에 대한 편의 문법이라고 주장하는 사람들은 더 적다. 시점에 따라 편의 문법에 대한 모호한 정의가 달라지기 때문에 판단이 더 복잡해진다. 

구조체가 처음 도입된 시점의 코드들은 배열을 주로 사용했기 때문에, 구조체는 지금보다더 편의 문법처럼 보였다. 하지만 오늘날에는 프로그래머가 구조체를 염두에 두고 프로그램을 작성하기 때문에 예전보다 구조체가 훨씬 더 근본적인 프로그래밍 언어 요소인 것처럼 여겨진다.

일시를 표현하는 데이터 구조처럼 복잡한 데이터 타입을 마치 프로그래밍 언어가 기본 제공하는 데이터 타입처럼 사용할 수 있다. 밑은 일시를 나타내는 구조체 한 쌍과 이름을 나타내기 위한 배열을 함께 조합해 사용하는 모습을 보여준다.

```
start : hours(1)-minites(1)-seconds(1)-year(2)-month(1)-day(1)
end   : hours(1)-minites(1)-seconds(1)-year(2)-month(1)-day(1)
event_name : string(???)
```

구조체가 예상보다 메모리를 더 많이 차지하는 경우가 종종 있다. '메모리'절에서 메모리 정렬에 대해서 설명했을 때 32비트 컴퓨터에 맟춰 구획이 나눠진 영역에 일시를 표현하는 구조체를 만드는 경우라고 하자. 프로그래밍 언어는 멤버 순서가 바뀌면 문제가 될 수도 있기 때문에 프로그래머가 지정한 멤버 순서를 지킨다. 하지만 언어는 메모리 정렬도 지켜야 한다. 따라서 연도를 4번째와 5번째 바이트에 위치시키면 경계에 걸치기 때문에 패치를 패딩을 통해 바꿔야 한다. 실제 메모리 배치는 다음과 같다.

```
hours(1)-minites(1)-seconds(1)-padding(1)-year(2)-month(1)-day(1)
```

패딩을 사용하는 대신 구조체 멤버 순서를 바꿔서 7바이트만 사용할 수도 있다. 물론 이런 구조체를 2개 이상 이벤트 구조체에 넣으면 언어는 다시 패딩을 넣어서 각 구조체를 8바이트 경계에 위치시킨다.

실제 날짜와 시간은 32비트 수를 사용하고 현재는 64비트까지 확장한 상태이다.





### 단일 연결 리스트

배열은 실제 데이터만 저장하고 데이터 관리를 위한 부가 정보를 따로 요구하지 않는다. 하지만 데이터 양이 정해져 있지 않는 경우에는 배열이 적합하지 않다. 배열을 충분히 크게 만들지 않으면 계속 배열을 만들고 복사해야 한다. 그렇다고 필요 이상으로 배열의 크기를 잡아놓으면 메모리를 너무 낭비하게 된다.

연결 리스트(linked list)는 목록에 들어갈 원소 개수를 모르는 경우 배열보다 더 잘 작동한다. 단일 연결 리스트는 구조체를 사용해 만들 수 있다.

```
헤드 -> next -> next -> next -> NULL
       data    data    data
```

next는 리스트의 다음 원소를 저장하는 포인터다. 리스트에서 맨 앞은 헤드(head)라고 알려져 있다. 리스트의 마지막은 테일(tail)이다. 다음 원소가 정상적인 리스트원소가 아니기 때문에 테일을 쉽게 알아볼 수 있다. 보통 NULL 포인터로리스트 원소가 아님을 표현한다.

리스트와 배열의 가장 큰 차이는 배열의 각 원소는 메모링에서 연속적으로 위치하지만, 리스트 원소는 메모리에서 아무 위치에서나 있을 수 있다는 점이다. 리스트에는 원소를 쉽게 추가할 수 있다. 헤드 앞에 새 원소를 위치시키면 된다.

```
next -> 헤드(x) -x> next
data 							 data
```

원소 삭제의 경우 삭제할 리스트 원소의 바로 앞 요소가 다음 next를 가리키게 하면 된다.

```
next -x> next -> next
data     data    data
```





### 동적 메모리 할당

연결 리스트의 원소 삽입을 설명하면서 새 노드를 삽입하는 방법은 설명했지만 새 노드를 위한 메모리를 얻을수 있는 지에 대해서는 설명하지 않았다.

프로그램 데이터 공간의 구성을 설명할 때 정적으로 할당된 데이터 영역 다음에 프로그램 런타임 라이브러리가 설정해주는 힙 영역이 있다고 했다. 별도의 메모리 관리 유닛(MMU : memory management unit)이 없는 컴퓨터라면 이 힙 영역이 프로그램에 사용할 수 있는 모든 데이터 메모리다.(스택과 인터럽트 벡터는 제외) MMU가 있는 시스템에서는 런타임 라이브러리가 프로그램에게 필요한 메모리 용량을 판단해 운영체제 에게 요청한다. 모든 메모리를 할당 받는 것은 불합리 하기 때문이다. 프로그램의 브레이크(break)는 프로그램이 사용할 수 있는 메모리의 끝을 뜻하는 말이다. 일부 시스템에서는 프로그램이 사용하는 메모리를 늘리거나 줄이는 시스템 콜을 제공하는 경우도 있다.

배열 등의 변수가 사용하는 메모리는 정적(static)이다. 이런 변수에 할당된 주소는 바뀌지 않는다. 리스트 노드와 같은 존재는 동적이다. 이들은 필요에 따라 생기기도 하고 사라지기도 한다. 이런 동적인 대상에 사용할 메모리를 힙에서 얻는다.

프로그램은 힙을 관리할 수 있어야 한다. 프로그램은 사용 중인 메모리를 알아야 하고, 사용 가능한 메모리도 알아야 한다. 이런 목적에 사용하는 라이브러리 함수로 C에는 malloc과 free가 존재한다.

Malloc 구현에는 단일 연결 리스트 데이터 구조를 사용해 작동하는 구현이 있다. 힙은 여러 블록으로 나뉘고, 각 블록에는 크기와 다음 블록에 대한 포인터가 포함된다.

```
-> next -> next -> next
   size    size    size
   data    data    data
```

처음에는 전체 힙이 한 블록으로 존재한다. 프로그램이 메모리를 요청하면 malloc이 충분한 크기의 블록을 찾아서 요청받은 공간에 대한 포인터를 돌려주고, 프로그램에게 할당한 메모리를 반영해 블록의 크기와 링크를 조정한다. 프로그램이 free로 메모리를 해제하면 메모리가 다시 연결 리스트에 추가된다.

malloc은 종종 가용 블록 리스트를 스캔하면서 두 가용 블록이 서로 인접한 경우 둘을 합쳐서 더 큰 블록으로 만든다. 메모리를 할당하려면 어차피 가용 블록 리스트를 스캔해야 하기 때문에 malloc이 호출될 때 이런 작업을 수행하는 방법도 있다. 시간이 지남에 따라   메모리 공간은 파편화(fragmentation)된다. 이 말은 메모리를 모두 다 사용하지도 않았는데 너무 작은 가용 블록들만 남아서 malloc으로 요청 받은 메모리를 돌려줄 수 없게 되었다는 뜻이다. MMU가 있는 시스템의 경우 필요할 때 더 큰 메모리를 얻기 위해 앞서 설명한 브레이크를 조정할 수 있다.

이렇게 연결 리스트를 사용하는 방법에는 부가 비용이 발생하는 데 64비트 컴퓨터라면 next와 size로 인해 블록당 16바이트가 소모된다.

경험이 적은 프로그래머는 할당되지 않은 메모리를 해제(free)하는 실수를 자주 저지른다. 반대로 이미 해제된 메모리를 계속 사용하는 실수도 종종 저지른다. 할당 받은 메모리 경계 밖에 있는 데이터를 계속 쓰면 size와 next 필드를 오염시킬 수 있다. 이런 실수는 size와 next가 필요한 연산(메모리 할당이나 해제)이 실행되기 전까지는 문제가 드러나지 않기 때문에 특히나 발견하기 어렵다.

기술 발전으로 인한 부작용으로 아주 작은 기계도 프로그램에게 필요한 양보다 훨씬 더 많은 RAM을 제공하는 경우가 종종 있다는 점을 들 수 있다. 이런 경우 부가 비용을 줄이고 메모리 할당 버그를 없앨 수 없기 때문에 모든 메모리를 정적으로 할당해 사용하는 편이 더 낫다.





### 더 효율적인 메모리 할당

텍스트 무낮열이 들어 있는 연결 리스트를 자주 볼 수 있다. 다음처럼 노드에 문자열을 가리키는 포인터가 포함된 연결 리스트가 있다고 하자.

```
node
next        문자열
string == c a t \0
```

이런 경우 노드에 사용할 메모리는 물론 문자열에 사용할 메모리도 할당해야 한다. malloc의 부가 비용이 상대적으로 커질 수 있다. 특히 64비트 컴퓨터에서는 16바이트 노드를 처리하기 위해 16바이트의 부가 비용이 필요하고 4바이트인 cat 문자열을 처리하기 위해 16바이트의 추가 비용이 더 필요하다.

노드와 문자열을 동시에 할당하면 이런 부가 비용을 줄일 수 있다. 노드를 할당한 뒤 문자열을 할당하는 것이 아니라 노드와 문자열의 크기를 합하고, 메모리 경계를 지키기 위해 필요한 패딩을 추가한 크기의 공간을 할당할 수 있다. 이 말은 노드를 할당한 메모리의 크기가 달라질 수 있다는 뜻이다. 이 방법은 부가 비용을 절반으로 줄여준다. 문자열이 cat인 경우 다음과 같다.

```
포인터
크 기
next
cat\0
```

이 접근 방법은은 노드를 삭제할 때도 더 효율적이다. 기존에 있던 방법은 free를 두 번 (한 번은 노드, 한 번은 문자열)을 호출해야 하지만 더 효율적인 경우에는 한 번만 free를 호출해도 된다.





### 가비지 컬렉션

동적 메모리를 명시적으로 관리하면서 포인터를 잘못 쓰면 두 가지 문제가 생긴다. 포인터는 단지 메모리 주소를 나타내는 숫자에 지나지 않는 다는 사실을 기억해라. 하지만 모든 숫자가 올바른 메모리 주소는 아니다. 포인터를 사용해 존재하지 않는 메모리에 접근하거나 프로세서의 메모리 경계에 맞지 않는 주소에 접근하면 예외가 발생하면서 프로그램이 중단된다.

자바나 자바스크립트 같은 언어에는 포인터가 없지만 직접 malloc이나 free를 하지 않으면서도 동적 메모리 할당을 지원한다. 이런 언어는 malloc이나 free 대신에 가비지 컬렉션(garbage collection)을 구현한다. 가비지 컬렉션은 1959년 미국의 컴퓨터 및 인지 과학자인 존 매카사가 LISP 프로그래밍 언어를 위해 발명한 방법이다. 부분적으로는 잘못된 포인터의 사용에 대한 후회로 인해 최근 가비지 컬렉션이 다시 떠오르기 시작했다.

자바 같은 언어는 포인터 대신 참조를 사용한다. 참조(reference)는 포인터를 추상화해서 거의 비슷한 기능을 제공하지만 실제 메모리 주소를 노출하지는 않는다.

가비지 컬렉션을 사용하는 언어에는 데이터 요소를 만들어내면서 이 요소가 사용할 메모리도 할당하는 `new` 연산자를 제공하는 경우가 자주 있다(C++처럼 가비지 컬렉션을 사용하지 않는 언어가 이 연산자를 제공하는 경우도 있다.). 데이터 요소를 삭제하는 경우에 대응하는 연산자는 없다. 대신 언어의 런타임 환경이 변수 사용을 추적해서 더 이상 사용하지 않는 메모리를 자동으로 해제해준다. 자동 해제를 구현하는 방법은 다양하다. 그 중에는 각 메모리를 변수가 참조하는 횟수를 추적해서 더 이상 메모리를 참조하는 변수가 없을 때 메모리를 해제하는 방법도 있다.(참조 카운팅 : 보통은 프로그램의 정적 변수, 스택을 포함하는 루트 집합이라는 변수의 모임이 존재하고 이 모임으로부터 참조되는 모든 메모리와 그 메모리들로부터 다시 참조되는 모든 메모리를 재귀적으로 구해서 전체 사용 중인 메모리를 파악한다.)

가비지 컬렉션도 트레이드 오프가 있다. 한 가지 문제는 프로그래머가 가비지 컬렉션 시스템을 제어할 수 없다는 점이다. 이는 LSI-11의 리프레시 문제('임의 접근 메모리' 참조)와 비슷하다. 이로 인해 프로그램이 아주 중요한 일을 하는 도중에 가비지 컬렉션 시스템이 작동돼서 문제가 생기는 경우도 있다. 그리고 불필요한 참조가 남는 경우가 자주 있기 때문에 프로그램이 메모리를 더 많이 사용하는 경향이 있다. 불필요한 참조는 메모리 재활용을 방해한다. 나쁜 포인터를 사용할 때처럼 프로그램이 오류로 중단되지는 않지만, 메모리 재활용이 늦어지면 프로그램이 느려진다. 포인터 사용 문제를 해결하려는 좋은 의도에서 가비지 컬렉션이 출발했짐나 불필요한 참조를 추적하는 작업 또한 실제로는 더 디버깅하기 어렵다는 사실이 드러났다.





### 이중 연결 리스트

단일 연결 리스트의 delete 함수에서는 포인터를 제대로 변경하기 위해 삭제하려는 원소의 바로 앞 원소를 찾아야만 했다. 이로 인해 단일 연결 리스트의 delete는 상당히 느리다. 경우에 따라 아주 긴 리스트를 순회해야 할 수 도 있다. 다행히 메모리를 더 사용하면서 이런 문제를 해결해주는 리스트 타입이 있다.

이중 연결 리스트(doubly linked list)는 노드에 다음 원소에 대한 포인터뿐만 아니라 이전 원소에 대한 포인터도 들어 있는 리스트다. 이로 인해 노드당 부가 비용은 2배가 되지만 delete 시 노드를 앞에서부터 방문할 필요가 없어진다. 따라서 이 또한 공간/시간의 트레이드 오프라고 할 수 있다.

```
<- prev <- prev <- prev
	 next -> next -> next ->
	 data    data    data
```

이중 연결 리스트의 장점은 리스트 전체를 방문하지 않아도 원하는 위치에 노드를 추가하거나 삭제할 수 있다는 점이다. 어떤 원소 뒤에 노드를 추가하는 방법은 

```
           new
   prev <- prev <- prev
	 next -> next -> next
	 data    data    data
```

이전의 노드의 next를 추가하려는 노드에 연결한 뒤 이전 노드의 prev값을 현재 노드에 위치시킨다.

삭제 역시 간단하다.

```
prev <- prev
next -> next
data    data 
```

prev를 바로 연결해주고 next를 바로 삭제하려는 노드 다음과 연결한다.

이중 연결 리스트에서노드 삭제나 삽입 연산을 할 때는 리스트를 순회할 필요가 없음을 알 수 있다.





### 계층적인 데이터 구조

지금까지는 선형적인(linear) 데이터 구조를 살펴봤다. 많은 애플리케이션의 경우 선형적인 데이터 구조로 충분하다. 하지만 선형성이 문제가 될 때가 있다. 왜냐하면 데이터 저장은 우리가 해야 하는 일의 절반에 불과하기 때문이다. 데이터를 효율적으로 가져오고 싶은 경우가 종종 있다. 예를 들어 연결 리스트에 저장된 물건들이 있다고 할 때 어떤 물건을 찾으려면 리스트를 순회해야만 한다. 리스트 길이가 n이라면 최대 n번 노드를 순회하면서 원하는 노드인지 비교를 해야 한다. 이 방법은 n이 크다면 실용적이지 않다.

연결 리스트의 노드를 연결하기 위해 포인터를 썼다. 노드에 들어갈 수 있는 포인터 수에는 제한이 없기 때문에, 상상력과 메모리 공간이 허용하는 한 원하는 대로 데이터를 조직할 수 있다. 예를들어 다음과 같은 방식으로 노드를 계층적으로 조직할 수도 있다.

```
			/			root     \
		left						right
```

가장 간단한 계층적 데이터 구조는 2진 트리(binary tree)이다. '2진'이라는 말은 노드가 최대 2개의 다른 노드와 연결될수 있기 때문에 붙은 이름이다. 트리의 루트(root)는 연결리스트의 헤드에 해당한다.

어떤 수열 `[8,6,9,4,5]`이 존재할 때 8부터 루트에 들어간 뒤 그 뒤에 들어가는 순서대로 현재 노드보다 작으면 왼쪽으로 위치되고 크면 오른쪽으로 위치된다. 그렇다면 다음과 같은 2진트리가 완성된다.

```
  8 
 6 9
4 5
```

이 데이터 구조에는 숫자가 5개 들어가 있지만 최악에 경우에도 logn만큼만 비교하면 원하는 숫자가 존재하는지 찾을 수 있다. n번 비교해야 하는 연결 리스트보다 성능이 더 좋다. 트리를 변경할 필요가 없으므로 노드를 가리키는 포인터를 가리키는 포인터를 만들 필요는 없다.

원소 삽입 순서에 따라 트리의 구조가 편향될 수도 있다.

```
4 
	5 
		6 
			8 
				9
```

이런 나쁜 경우는 단일 연결 리스트 처럼 보인다. 2진 트리의 장점을 없앨 뿐만 아니라 사용하지 않는 왼쪽 트리 포인터로 인해 더 많은 부가 비용을 지불해야 한다. 따라서 트리가 균형잡힌 모습을 유지하기를 기대한다.

2진 트리에서 어떤 대상을 검색하는 연산은 트리 깊이(depth)에 의해 정의되는 함수다. 만약 트리가 n계층 만큼 아래로 내려간다면 검색시 n번만 원소를 비교하면 된다. 연결된 리스트에서는 n번 비교를 해야 하는 반면, 균형 잡힌 트리에서는 logn번만 비교하면 된다. 

트리 균형을 회복하는 알고리즘은 아주 많다. 트리 균형을 다시 회복시키는 데는 시간이 걸리기 때문에 알고리즘 속도와 삽입/검색 시간, 재균형 시간 사이에 트레이드 오프 관계가 존재한다. 트리 균형 알고리즘은 계산 비용이 더 많이 들고 일부는 저장 공간도 더 사용한다. 하지만 n보다 logn이 훨씬 더 작기 때문에 트리 크기가 커질 수록 이런 부가 비용을 빠르게 극복할 수 있다.





### 대용량 저장장치

'블록 장치'에서 디스크 드라이브에 대해 학습하였는데 여기서는 포인터를 많이 다루면서 드라이브 데이터 구성의 특이점을 이해한다.

디스크의 기본 단위는 블록(block)이라고 하고 연속적인 블록을 클러스터(cluster)라고 한다. 클러스터는 한 트랙 안에 잇는 연속적인 섹터로 이뤄지므로, 데이터를 한 클러스터에만 저장할 수 있다면 좋을 것이다. 아주 높은 성능이 필요한 경우 이런 식으로 저장하는 경우도 있지만 일반적인 해법으로는 한 클러스터 내에 데이터를 저장하는 방식이 그리 바람직하지 다. 또한 한 클러스터 안에 들어가기에는 너무 큰 데이터도 있기 마련이다. 대신에 데이터는 사용 가능한 섹터가 있으면 위치와 관계없이 저장된다. 대신 운영체제의 장치 드라이버가 데이터가 연속적으로 저장된 것 같은 착각을 불러일으킨다. 이제 어떤 데이터를 저장하기 위한 저장소 블록을 찾는 대신, 어떤 데이터를 저장하기에 충분한 크기가 되도록 고저오딘 크기의 블록을 여럿 확보해서 데이터를 이런 블록에 나눠 담아야 한다.

연결 리스트는 순회에 시간이 너무 오래 걸리기 때문에 어떤 디스크 블록이 사용가능하고 어떤 블록이 사용 중인지 알아내기 위한 좋은 해법은 아니다. 예를 들어 8TiB 디스크에는 블록이 20억개가 존재하고 최악의 경우 250개의 블록을 읽기 위해서 1초가 걸리게 된다. 전체를 읽으려면 15년이 걸리며 이는 전혀 실용적이지 않다. 

데이터를 메모리상에서 관리할 때는 포인터를 통해 메모리를 참조하더라도 충분하다. 하지만 메모리에 있는 정보는 일시적(transient)이고 데이터를 장기적으로 저장할 때는 디스크를 사용하므로 데이터를 디스크에 저장하기 위해서는 영구적인 어떤 존재가 필요하다. 우리는 이미 그 대답을 알고 있다. 바로 파일 이름(filename)이 그 답이다. 이제 이런 파일 이름을 디스크에 저장할 방법과 파일 이름과 파일의 데이터가 저장된 디스크 블록을 연결해줄 방법이 필요하다.

이 모두를 처리할 방법이 바로 유닉스(UNIX)에서 나왔다. 블록 중 일부를 아이노드(inode)로 따로 지정한다. 아이노드는 디스크 블록에 대한 인덱스(index)와 노드(node)를 합친 단어이다. 따라서 아이노드는 인덱스 노드이다. 아이 노드에는 파일에 대한 여러 가지 정보가 들어간다. 이런 정보에는 이름, 크기, 소유자, 허가 내역 또한 파일의 데이터가 들어 있는 블록에 대한 인덱스도 포함된다.

```
아이노드 
 정보
  * --- 직접 블록
           * --- 간접 블록
                    * --- 2중 간접 블록
                              * --- 3중 간접 블록
                                         *
```

이 구조는 복잡해 보이지만 쉽게 이해할 수 있다. 아이노드에는 보통 직접 블록(direct block) 포인터(실제로는 블록의 인덱스)가 12개 있다. 따라서 직접 블록을 통해서 최대 4096 \* 12 바이트까지 데이터를 보관할 수 있다. 대부분의 파일은 이 정도로 충분하다. 파일이 더 커지면 간접 블록(indirecrt block)을 사용하기 시작한다. 32비트 인덱스를 사용하면 한 블록(4KiB)에는 인덱스가 1024개 있으므로 간접 블록을 통해서는 최대 4MiB까지 지원할 수 있다. 만약 이보다 더 큰 파일을 저장해야 하면 2중 간접(double indirect) 블록을 통해 4GiB까지 3중 간접(triple indirect) 블록을 통해 4PiB까지 지원할 수 있다.

아이노드 정보 중에는 블록에 데이터가 있는 지 디렉토리(directory) 정보가 있는 지를 표시하는 것도 있다. 디렉토리는 파일 이름과 파일 데이터를 가리키는 아이노드를 연결해 준다. 유닉스가 파일을 처리하는 방식이 멋진 이유로 디렉토리가 단지 파일의 여러 유형 중 하나에 불과하다는 점을 들 수 있다. 이 말은 디렉토리가 다른 디렉토리를 참조할 수 있다는 뜻이고 이로 인해 우리가 트리 구조의 계층적 파일 시스템(hierachical filesystem)이 생겨 났다.

현 시점에서 보면 이 모든 구조가 임의의 트리처럼 생각될 것이다. 하지만 실제로는 그렇지 않다. 이런 구조에서 여러 아이노드가 같은 블록을 참조할 수 있다. 각 참조를 링크(link)라고 부른다. 링크로 인해 같은 파일(같은 파일에 담긴 데이터)이 여러 디렉토리에 나타날 수 있다. 그리고 디렉토리에 대해 링크를 할 수 있으면 편리하다는 사실도 알게 됐다. 이를 위해 심볼릭 링크(symbolic link)가 발명됐다. 하지만 심볼릭 링크를 허용하는 파일 시스템 그래프에 루프가 생긴다. 이로 인해 무한 루프를 감지하기 위한 특별한 코드가 필요하다. 이제 사용 중인 블록에 대한 정보를 저장할 수 있는 복잡한 구조가 생겼다. 하지만 가용 공간(free space)을 추적하는 효율적인 방법이 아직 없다.

가용 공간을 추적하는 방법으로 각 블록을 1비트로 표현하는 비트맵을 사용한 방식을 들 수 있다. 이 방법을 사용하면 비트맵이 아주 커질 수 있다. 8TB 디스크 드라이브를 다루기 위해서는 20억 비트가 필요한데, 이는 256MB의 공간이다. 물론 이 방법도 전체 디스크의 0.1%보다 더 적은 공간을 사용하고 모든 비트맵 데이터가 항상 메모리에 있을 필요는 없으므로 충분히 채택할 만 하다.

비트맵을 사용하면 간단하면서 효율적이다. 특히 64비트 워드를 다룰 수 있으면 더욱 더 효율적이다. 1이 사용 중인 블록을 가리키고 0이 사용 가능한 블록을 가리킨다고 생각하면, 모든 비트가 1이 아닌 워드를 쉽게 찾을 수 있다.

하지만 이 접근에는 파일 시스템 그래프와 가용 공간을 나타내는 비트맵 사이에 동기화가 깨질 수 있다는 문제가 있다. 예를 들어 디스크에 데이터를 기록하는 도중에 전원이 나갈 수 있다. 이전에는 동기화가 깨지게 되면 아이노드를 조작해 파일 시스템을 수리해야만 했다. 파일 시스템 그래프를 뒤지면서 가용 블록 데이터와 비교해주는 fsck 등의 프로그램이 개발되면서 이런 일은 사라졌다. fsck는 더 나은 접근 방법이지만 디스크가 커짐에 따라 fsck에 걸리는 시간도 계속 늘어 났다. 이제는 오류를 더 효율적으로 수정할 수 있도록 설계된 저널링 파일 시스템이 널리 쓰이고 있다.

* 저널링 파일 시스템

  저널링 파일 시스템은 디스크에서 실제 가용 공간 비트맵과 아이노드, 디렉토리를 변경하기 전에 저널 이라고 하는 특별한 디스크 영역에 어떤 연산을 수행할지에 대한 정보를 기록한다. 저널에 데이터가 기록되지 않은 상태에서 디스크 다른 부분에 변경이 가해지는 일은 없다. 파일 시스템을 변경하다 문제가 생기면 저널 데이터를 보고 수행되지 않은 연산을 다시 수행하여 파일 시스템을 최신 상태로 복구할 수 있고, 저널에 데이터를 기록하다 문제가 생기면 해당 부분은 복구가 불가능하지만 파일 시스템은 깨지지 않은 저널에 데이터를 기록하기 직전의 상태를 유지할 수 있다. 저널에 데이터를 기록하는 시간은 파일 시스템에 데이터를 기록하는 시간보다 훨씬 적게 걸려 전원 오류 등이 발생핼 때 저널이 깨질 확률보다 파일 시스템의 다른 부분이 깨질 확률이 높다.





### 데이터베이스

2진 트리는 데이터를 메모리에 저장할 때는 훌륭한 방법이지만 메모리 안에 들어갈 수 없을 정도로 커다란 데이터를 저장할 때는 그리 잘 작동하지 않는다.  트리 노드는 크기가 작은 경향이 있어서 디스크 섹터에 잘 들어 맞지 않기 때문이다.

데이터베이스(database)는 정해진 방식으로 조직화된 데이터 모음이다. 데이터베이스 관리 시스템(DBMS database management system)은 데이터베이스에 정보를 저장하고 읽어올 수 있게 해주는 프로그램이다. DBMS는 보통 맨 아래의 데이터 저장 메커니즘을 감싼 여러 계층의 인터페이스로 구성된다.

데이터베이스는 독일 컴퓨터과학자 루돌프 바이어와 미국 과학자 에드 맥크레이트가 보잉사에서 개발한 1971년 B 트리라는 데이터 구조를 활용한 시스템이다. B 트리는 균형 트리이지만 2진 트리는 아니다. B트리는 균형 2진 트리보다는 공간을 덜 효율적으로 사용하지만 성능이 더 나속, 특히 디스크에 데이터를 저장할 때 균형 2진 트리보다 더 성능이 좋다. B 트리는 메모리 아키텍처에 대한 이해가 더 효율적인 코드를 작성하는 데 도움이 되는 또 다른 경우라 할 수 있다. 

이름을 알파벳 순으로 저장하는 균형 2진 트리가 있다고 하자. 이 트리는 다음과 같다.

```
         ken
   dennis     rob
brian doug mike steve
```

B 트리 노드에는 2진 트리 노드보다 더 많은 가지가 있다. 가지의 수는 디스크 블록 하나를 정확히 꽉 채울 수 있는 숫자로 결정된다.

```
                         A...Z
    A...M                         N...Z
brian dennis doug ken mike     rob steve
```

위를 보면 내부 노드는 균형이 잡혀 있고 이로 인해 검색 시간을 미리 예측할 수 있다. 위를 보면 공간만 차지하는 사용하지 않는 자식 링크가 존재한다. 사용할 수 있는 자식 링크가 없으면 각 노드가 담당하는 범위를 조장하면서 쉽게 트리의 균형을 다시 잡을 수 있다. 예를 들어 A-M 노드의 자식을 모두 할당한 경우, 이를 A-G와 H-M 노드로 나눌 수 있다. 보통은 자식 숫자가 2의 지수 인 경우에 노드를 나눈다.

노드에 저장하는 키 수가 더 많음녀 노드를 디스크에서 더 적게 읽어올 수 있다. 노드 크기가 커져도 디스크 블록에 들어맞기 때문에 아무 문제가 되지 않는다. 어차피 디스크에서 데이터를 읽어올 때는 한 블록을 한 덩어리로 읽어오기 때문이다. 사용하지 않은 자식 링크로 인해 낭비되는 공간이 있지만 이런 비효율성은 합리적인 트레이드 오프라고 할 수 있다.





### 인덱스

정렬된 데이터에 접근하면 효율적이다. 하지만 저장된 데이터를 여러 가지 방법으로 접근해야 할 수도 있다. 예를 들어 이름과 성을 기준으로 접근할 수도 있지만 이름과 더 선호하는 가수를 기준으로 데이터에 접근할 수도 있다.

다음은 이름으로 조직화된 노드를 보여준다.

```
이름 인덱스                                    성 인덱스
                 A-M  brian kerr   
  A-Z                               A-M
  	             N-Z  nic claxston            A-Z
  	                  rob pike      N-Z 
```

이렇게 구성된 노드를 보통 주 인덱스(primary index)라고 부른다. 하지만 인덱스가 둘 이상이 될 수도 있다. 인덱스가 여럿이면 다양한 방법으로 원하는 데이터를 효율적으로 검색할 수 있다.

인덱스의 경우 유지보수를 해야 한다는 트레이드 오프가 있다. 데이터가 바뀔 때마다 모든 인덱스를 갱신해야 한다. 하지만 데이터 변경보다 데이터 검색이 더 자주 벌어지기 때문에 이런 갱신 비용은 지불할 만한 비용이다.





### 데이터 이동

앞에서 연결 리스트 대신 배열을 사용하려면 배열 크기를 증가시킬 필요가 있을 때마다 데이터를 복사해야 한다고 말했다. 페이지 테이블을 MMU에 넣거나 꺼낼 때, 디스크 비트맵을 디스크에 저장하거나 디스크에서 읽어올 때와 같은 시점에 복사를 해야 한다. 프로그램은 한 지점에서 다른 지점으로 데이터를 이동시키기 위해 많은 시간을 소비하므로 효율적으로 하는 것이 중요하다.

다음은 메모리 블록을 0으로 설정하는 방법이다.

```
curr <- 0으로 설정할 메모리의 맨 앞 바이트의 주소
length > 0? - no > 완료
curr가 가리키는 메모리 == 0
curr = curr +1
length = length -1; 다시 length가 0인지 부터 검사
```

이 알고리즘은 잘 작동하지만 효율적이지 않다. 각 단계를 실행하기 위해 똑같은 시간이 걸린다고 가정하면 메모리 위치를 0으로 설정하는 데 걸리는 시간보다 인덱스를 유지하고 길이를 갱신하기 위한 시간이 더 걸린다. 루프 언롤링(loop unrolling) 기법을 사용하면 다음과 같이 더 코드를 효율적으로 만들 수 있다. 예를 들어 length가 짝수라면 루프를 펼쳐서 잡다한 관리에 시간을 쓰기보다 메모리를 0으로 만드는 데 더 많은 시간을 쓰게 할 수 있다.

```
curr <- 0으로 설정할 메모리의 맨 앞 바이트의 주소
length > 0 - no -> 완료
curr가 가리키는 메모리 == 0
curr += 1
curr가 가리키는 메모리 == 0
curr += 1
length -= 2; 다시 length가 0인지 부터 검사
```

더 일반적인 구현이 있다면 실제로 더 일반적인 구현이 있다. 캐나다 프로그래머 톰 더프는 영화 제작사 루카스필름에서 일할 때 데이터 복사를 빠르게 해주는 더프의 장치를 발명했다. 이 접근 방법은 0 이상일 때만 제대로 작동한다.

더프의 장치는 루프를 8번 펼치고 남은 바이트 수에 따라 적당한 위치부터 펼친 루프의 단계를 시작한다. 루프를 더 펼치고 싶겠지만 이런 접근 방식이 제대로 작동하려면 언롤한 코드가 명령어 캐시 안에 유지돼서 성능을 최대한 발휘할 수 있도록 적절히 균형을 잡아야만 한다.

효율성을 높이는 또 다른 방법은 64비트 기계라면 한꺼번에 8바이트를 0으로 설정할수 있다는 사실을 활용하는 것이다. 물론 블록 맨 앞이나 뒤에 메모리 경계에서 벗어난 남는 바이트들을 처리하기 위한 코드를 추가해야 한다.

단지 메모리의 내용을 어떠한 값으로 설정하지 않고 데이터 블록을 복사하려고 하면 이 모든 과정이 더 복잡해진다. 경우에 따라 원본과 복사본의 메모리 경계가 서로 같지 않을 수도 있기 때문이다. 하지만 워드 경계에 블록이 위치하는 경우가 더 많으므로 일단 원본과 복사본이 워드 경계에 위치하는지 먼저 검사해 볼만한 가치가 있다.

복사를 구현할 때 생기는 복잡한 문제가 하나 더 있다. 이 문제는 어떤 메모리 영역 안에서 데이터를 이동하기 위해 복사를 사용하는 경우가 흔하기 때문에 생기는 문제다. 예를 들어 공백으로 구분된 단어로 가득찬 버퍼가 있는데, 버퍼 안에서 첫 번째 단어를 읽은 후, 메모리 확보를 위해 첫 번째 단어를 없애고 그 외의 모든 단어를 버퍼의 맨 앞으로 옮기고 싶다고 하자. 이런 식으로 영역이 겹치는 경우 복사 시 조심해야 한다. 경우에 따라서는 데이터를 덮어쓰는 일은 방지하기 위해 복사를 역방향으로 진행해야 할 수 있다.

폽 파이크가 벨 연구에서 1980년대 초  개발한 초기 래스터 그래픽 터미널인 블릿(blit)을 들 수 있다. 당시는 화면 처리를 위한 전용 IC를 만드는 게 그다지 실용적이지 않은 시대 였다. 원본과 대상 데이터가 겹칠 수도 있었고(예를 들어 창을 드래그할 경우), 비트 데이터가 메모리상에서 어떤 경계에든 위치할 수 있었다. 당시에는 프로세서가 빠르지 않아 성능이 아주 중요했다. 블릿은 모토로라 68000을 사용했다. 68000에는 MMU가 없었기 때문에 파이크는 원본과 복사본의 주소를 고려해 복사를 빠르게 할 수있도록 최적의 코드를 그때그때 생성해 내는 코드를 작성했다. 이런 방식은 자바 등 여러 언어의 가상 머신에서 사용중인 JIT(just in time : 즉시 컴파일)의 선조라 할 수 있다.





### 벡터를 사용한 I/O

시스템 성능에 있어 데이터를 효율적으로 복사하는 것이 중요하다. 하지만 복사를 아예 피할 수 있으면 성능을 더 높일 수 있다. 운영체제와 사용자 공간 프로그램 사이에는 데이터가 아주 많이 오고 간다. 그리고 이런 데이터가 연속적인 메모리에 위치하지 않는 경우도 자주 있다.

mp3 형식의 오디오 데이터를 생성해 오디오 장치에 보내고 싶을 때 다른 파일 형식과 마찬가지로 mp3 파일은 여러 프레임(frame)으로 구성되며, 각 프레임은 헤더(header)와 데이터로 구성된다. 다음과 같은 전형적인 오디오 파일에는 헤더가 똑같은 프레임이 다수 존재한다.

```
헤더 
CRC
사이드 정보
주 데이터
부수 데이터
```

모든 데이터를 한 버퍼로 복사해서 프레임을 만들 수도 있다. 하지만 이 후 이 데이터를 오디오 장치에 써야 하기 때문에 또 한 번 데이터를 복사해야 한다. 대신에 프레임을 이루는 각 부분을 별도로 기록할 수도 있지만 이런 방법을 쓰면 문맥 전환(context switching) 비용이 늘어나고, 프레임 중 일부만 오디오 장치에 기록된 경우 오디오 장치가 문제를 일으킬 수 있다.

이럴 때 시스템에게 프레임의 각 부분을 가리키는 포인터의 집합을 전달하고, 시스템이 오디오 장치에 데이터를 쓸 때 각 부분을 하나로 합쳐주면 더 효율적이다. 밑의 방식은 충분히 가치가 있기 때문에 이런 방식을 지원하는 시스템 콜(redv, writev)도 있다.

```
벡터
크기 --- 헤더
크기 --- CRC
크기 --- 사이드 정보
크기 --- 주 데이터
크기 --- 보조 데이터
```

아이디어는 크기와 데이터에 대한 포인터로 이뤄진 벡터(같은 데이터가 연속적으로 모여 있는 고정된 크기의 데이터 구조)를 운영체제에 넘기는 것이다. 운영체제는 이 벡터에 저장된 데이터를 사용해 순서대로 오디오 프레임을 조합한다. 데이터를 쓸 때, 읽을 때 모두 벡터를 사용할 수 있다. 벡터를 활용해 데이터를 쓰는 행위는 여러 위치에서 데이터를 모아서 쓰므로 수집(gathering)이라고 부르고, 벡터를 사용해 데이터를 읽는 행위는 여러 위치로 데이터를 분산시키므로 분산(scattering)이라고 부르며, 둘을 아울러 분산/수집이라고 부른다.

분산/수집은 인터넷의 근간이 된 버클리 네트워크의 주류가 됐다. TCP/IP에서 IP데이터가 패킷으로 전달되고, TCP는 패킷이 올바른 순서로 전달되게 할 책임이 있다고 설명했다. 통신 종단점(endpoint : 여기서는 소켓)으로부터 도착하는 패킷은 사용자 프로그램에게 전달되기 전에 연속적인 스트림으로 수집된다.





### 객체 지향의 함정

자바, C++, 파이썬, JS 등의 객체 지향(object-oriented) 언어을 알고 있는 사람이 있을 것이다. 객체 지향 프로그래밍은 훌륭한 방법론이지만 주의 깊게 사용하지 않으면 성능 문제가 발생할 수도 있다.

객체 지향 프로그래밍은 C++를 통해 본격적으로 널리 사용되기 시작했다. C++는 처음에 C 위에서 만들어졌기 때문에, 내부 동작이 어떻게 되는지를 살펴볼 수 있는 기회를 제공한다는 점에서 흥미롭다.

객체(object)에는 함수에 해당하는 메서드(method)와 데이터에 해당하는 프로퍼티(property)가 들어 있다. 어떤 객체에 필요한 모든 데이터와 함수는 한 데이터 구조 안에 모여 있다. C는 타입 캐스팅(type casting)과 포인터, 특히 함수를 가리키는 포인터를 지원하기 때문에 이런 데이터 구조에서 큰 이점을 제공한다. 객체를 표현하는 C 구조체는 아마 다음과 비슷할 것이다.

```
객체
self          : 자기 자신
parent        : 부모 객체
constructor   : struct object *new () {...}
destructor    : void gozer() {...}
method 1      : void method1 () {...}
method ...
property 1    : ...
property ...
```

property 1처럼 정숫값 등 크기가 작은 데이터를 저장하는 프로퍼티는 객체 구조체 안에 들어간다. 반면 메모리 할당이 더 필요한 프로퍼티는 객체 구조체 안에 있는 포인터를 통해 참조된다.

메서드가 아주 많거나 하면 이 구조체가 아주 커질 수도 있다. 다음처럼 메서드를 별도의 데이터 구조에 나눠 담으면 이런 문제를 해결할 수 있다. 이 또한 시간/공간 트레이드 오프의 예라 할 수 있다.

```
객체
self         : 자기 자신
parent       : 부모 객체         메서드
methods           -----     constructor    :  struct object *new() {...}
property 1   :               destructor    :  void gozer() {...}
property 2   :                method 1     :  void method() {...}
property ...                  method 2
```

덴마크 프로그래머 비야네 스트롭스트룹이 C++를 만들기 전부터 프로그래머들은 이런 접근 방법을 사용해왔다. 최초의 C++는 C로 변환되는 언어였으며 이런 접근 방법을 통해 객체를 표현했다.

왜 이런 구조가 문제가 될까? 객체지향 사상가(ideologue)들은 객체가 모든 문제를 해결할 수 있는 해답이라고 생각한다. 하지만 객체와 관련된 부가 비용이 어느 정도 존재한다. 객체는 전역적으로 알려진 함수 대신에 자신이 사용할 메서드에 대한 포인터를 가지고 다녀야 한다. 따라서 객체 내의 데이터가 데이터만 저장하는 데이터 구조처럼 꽉 짜여 있지 않다. 성능이 결정적으로 중요할 때는 전통적인 배열을 활용하라.





### 정렬

데이터를 정렬해야 할 이유가 많이 있다. 그리고 정렬된 형태로 저장하고 싶은 경우도 자주 있는 데 데이터를 정렬해서 저장하면 메모리 접근 횟수를 줄일 수 있기 때문이다.

정렬은 오래된 주제이며 잘 만들어진 정렬 함수가 존재한다. 하지만 몇가지를 염려해야 한다.

우선 정렬 대상이 포인터 크기보다 크다면 데이터를 직접 정렬하는 대신 데이터를 가리키는 포인터를 재배열 하는 방식으로 정렬해서 데이터 자체가 여기 저기로 이동하지 않게 만들어야 한다.

또 정렬을 위한 관례가 어떻게 변해왔는 지 기억하라. 예를 들어 트리 예제에서는 산술적인 비교를 통해 결정을 내일 수 있었다. 어떤 수가 다른 수보다 큰지, 같은 지, 작은지에 따라 결정을 내렸다. 이런 의사결정 방법은 1956년 생긴 포트란(FORTRAN) 프로그래밍 언어에서 비롯됐다. 포트란에서는 다음과 같은 문장을 쓸 수 있다.

```fortran
IF (condition) branch 1, branch 2, branch 3
```

이 `IF`문은 식을 계산한 후 그 결과가 0보다 작으면 분기 1, 0과 같으면 분기 2, 0보다 크면 분기 3이 되나.

수 정렬은 아주 단순하다. 그래서 수 정렬에 사용한 원칙을 그대로 다른 대상을 정렬할 때도 적용할 수 있으면 좋을 것이다. 그림에서 리스트 노드에 임의의 정보를 포함시킬 수 있다고 했다. 트리나 그 밖의 데이터 구조도 마찬가지다.

유닉스 버전 3부터 전통적인 퀵정렬(quicksort) 알고리즘을 구현한 `qsort`라는 라이브러리 함수가 도입됐다. 이 `qsort` 구현에서 흥미로운 부분은 이 함수가 데이터를 정렬하는 방법은 알고 있지만 데이터를 비교하는 방법은 알지 못한다는 점이다. 그래서 `qsort`는 C 언어의 함수 포인터(함수를 가리키는 포인터)를 활용한다. `qsort`로 리스트를 정렬하려면 포트란 `IF` 문처럼 두 원소 a와 b가 있을 때 이 둘을 비교해서 a>b이면 0보다 큰 값, a==b는 0, a<b는 0보다 작은 값을 돌려주는 함수를 가리키는 포인터를 함께 전달해야 한다.이런 시스템은 후 여러 시스템에 도입됐다.

표준 C라이브러리의 문자열 비교인 `strcmp`는 `qsort`의 비교 함수를 염두에 두고 작성됐다. 그래서 두 문자열을 비교하면 0보다 작은 정수, 0, 0보다 큰 정수를 반환한다. 그리고 이런 비교 방식이 사실상 표준이 됐다.

처음 만들어진 아스키 코드를 바탕으로 하는 strcmp는 그냥 두 문자열을 첫 번째 글자부터 차례로 방문하면서 한 문자에서 다른 문자를 빼는 방식으로 구현됐다. 뺄셈 결과가 0이면 다음 문자로 진행하고 0이 아니면 바로 뺄셈 결과를 반환하며 이 과정을 반복하다가 문자열의 끝에 동시에 도달하면 0을 반환한다.

숫자가 저장된 두 리스트를 서로 비교한다면 이런 방법이 잘 작동하지만, 문자열을 알파벳순으로 정렬해야 한다면 어떨까? 아스키로 표현한 문자열만 정렬한다면 이 알고리즘은 잘 작동한다. 다른 지역을 지원해야 한다면 문제가 생긴다. 다른 언어를 지원하게 되면서 아스키 문자만 제대로 수치적인 비교 순서(collating order)를 제공하거나 언어에 따라 정렬 규칙이 달라진다는 부작용이 생겼다. 로케일을 제대로 지원하는 문자열 비교라면 이 두 단어를 같은 단어로 인식해야 한다.





### 해시

지금까지 살펴본 검색 메서드는 모두 데이터 구조를 순회하면서 비교를 여러 번 수행해야 했다. 하지만 경우에 따라 더 성능이 좋은 또 다른 접근 방법이 있는데, 바로 해싱(hashing)이다. 해싱은 다양하게 응용할 수 있다. 여기서는 대용량 저장장치나 메모리에 데이터를 저장하고 읽는 연산을 다룬다. 일반적인 개념은 검색에 사용할 키(key : 검색 시 동일성을 판정하는 기준)에 대해, 이들을 균일하게 벽에 흩뿌려주는 해시 함수(hash function)를 적용하는 것이다. 해시 함수가 계산하기 쉽고 각 키를 벽에서 유일한 위치에 뿌려준다면, 검색을 아주 빠르게 할 수 있다. 물론 실제로는 실용성을 위해 고려해야 할 부분이 있다.

해시 함수의 결괏값을 위해 키에 대응하는 데이터를 메모리에 저장할 수 있다. 따라서 해시 함수는 메모리 크기보다 작은 범위의 값을 만들어내야 한다. 해시 함숫값의 범위가 너무 크면 데이터를 너무 많이 사용하거나, 데이터가 너무 여기저기 흩어져서 메모리 접근 성능이 떨어질 수 있다. 키에 대한 사전 정보가 없기 때문에 완벽한 해시 함수를 만드는 것은 불가능하다.

저장 장치에 데이터를 저장하는 방법 중에는 해시 함수의 결과를 배열 인덱스로 활용하는 방법이 잇다. 이런 배열을 해시 테이블(hash table)이라고 말한다. 다음을 보라. 이 때 배열의 각 원소를 버킷(bucket)이라고 한다.

```
검색 키 -> 해시 함수 -인덱스> 해시 테이블
							0
							1
							2
```

어떤 특성을 지닌 함수가 좋은 해시 함수일까?  좋은 해시 함수는 계산하기 쉬워야하고, 키를 골고루 버킷에 뿌려줘야 한다. 텍스트에 대해 꽤 잘 작동하는 해시 함수로는 문잣값을 모두 더하는 함수가 있다. 이런 함수는 합계가 해시 테이블 인덱스 최댓값보다 커질 수 있다는 문제가 있지만, 합계를 해시 테이블 크기로 나눈 나머지를 사용하면 쉽게 이 문제를 해결할 수 있다. 실제 이런 함수가 어떻게 작동하는지 살펴보자. 해시 테이블 크기는 11이다. 문잣값을 모두 더한 값이 골고루 분포하기 위해서는 해시 테이블 소수(prime number)로 만들면 좋다.

노래 'Hello'를 버킷에 넣는다. 이 경우 버킷 인덱스는 4다. 다음 노래인 'Touch'는 버킷 9에 들어가며, 'Scalet'이 버킷 3에 들어간다. 하지만 'Alligator'의 경우 해시 함수 값이 'Scalet'과 같으면 충돌(collision)이라고 부른다.

```
3 Scalet Alligator
4 Hello
9 Touch
```

이 경우 해시 체인(hash chain)을 상요해 문제를 해결할 수 있다. 가장 간단한 형태의 해시체인은 싱글 링크드 리스트를 사용한다.

```
3 * - Scalet - Alligator
4 * - Hello
9 * - Touch
```

해시 체인을 관리하는 경우 몇 가지 선택지가 있다. 충돌이 일어나면 삽입을 빠르게 하기 위해 체인의 맨 앞에 원소를 추가할 수도 있다. 하지만 체인이 길어질 경우 검색 시간이 느려진다. 따라서 삽입 정렬(insertion sort)로 해시 체인에 원소를 넣을 수도 있다. 이 경우 삽입에 시간이 더 걸리지만 어떤 원소가 체인에 들어 있는 지 여부를 결정하기 위해 체인을 다 뒤질 필요는 없어진다. 해시 충돌을 처리하는 다른 방법도 많다. 해시 충돌을 처리하는 다른 방법도 많다. 예를 들어, 해시 테이블에서 빈 슬롯을 어떤 식으로든 찾는 알고리즘을 써서 해시 체인을 없앨 수 있다.

저장할 데이터 개수를 미리 알지 못하면 해시 테이블 크기를 잘 고르기는 어렵다. 체인 길이를 추적하다가 체인이 너무 길어지기 전에 해시 테이블을 확장할 수도 있다. 해시 테이블 확장은 비용이 많이 드는 연산이지만 검색에 비해 자주 발생하는 연산이 아니므로 결국에는 테이블 확장으로부터 이익을 얻을 수 있다.

해시 함수에도 변형이 많다. 해시 함수에서 성배는 완전 해시(perfect hash)이다. 완전 해시는 각 키를 유일한 버킷에 연결해준다. 모든 키를 미리 알고 있지 않으면 완전한 해시 함수를 만들기는 거의 불가능하다. 하지만 수학자들은 훨씬 더 좋은 함수를 만들어왔다.





### 효율성과 성능

컴퓨터 과학자들은 효율적인 검색 알고리즘을 만들기 위해 수많은 노력을 기울여왔다. 이런 노력 중 대부분은 컴퓨터가 비싼 시절에 이뤄졌다. 당시에는 성능과 효율성이 서로 연결되어 있었다.

전자 장치의 값이 극적으로 줄어든 지금은 성능과 효율성이 서로 분리됐다. 덜 효율적인 알고리즘을 돌려도 더 많은 프로세서를 사용하면 더 효율적인 알고리즘을 더 적은 프로세서에서 실행할 때보다 더 나은 성능을 얻을 수도 있다.

성능과 효율이 분리된 상황을 응용하는 방법으로 데이터베이스 샤딩(hsarding)이 있다. 샤딩은 다른 말로 수평 파티셔닝(horizontal partitionaing)이라고도 부른다. 샤딩은 다음 처럼 데이터베이스를 각각 다른 기계에서 실행되는 여러 샤드로 나누는 방식을 말한다.

```
          샤드 1
저장 장치  < --- > 프로세서 1 < --- > |
          샤드 2                   |
저장 장치  < --- > 프로세서 2 < --- > 컨트롤러 < --- > 인터페이스
          샤드 3                    |
저장 장치  < --- > 프로세서 3 < --- >  |
```

인터페이스를 통해 요청이 들어온 데이터베이스 연산을 모든 샤드에 전달한다. 그리고 컨트롤러가 결과를 하나로 모은다. 이 기법을 사용하면 작업을 여러 작업자로 나눠(병렬적으로) 수행할 수 있기 때문에 성능이 향상된다.

샤딩의 변종으로 맵리듀스(MapReduce)가 있다. 맵리듀스는 근본적으로 컨트롤러가 중간 결과를 모으는 방법을 코드로 직접 작성할 수 있게 해준다. 이를 활용하면 '모든 수학 강의의 학생수를 세라'와 같은 연산을 모든 학생의 목록일 읽어와 세어 보지 않고도 처리할 수 있다.

이런 다중 프로세서를 사용하는 방식을 응용할 수 이쓴 분야는 데이터베이스 뿐만이 아니다. 역사적으로 재미있었던 응용으로는 1998년 전자 프론티어 재단이 만들었던 DES(Data Encryption Standard) 암호 해독 프로그램이 있다. 이들은 1856개의 전용 프로세서 칩을 사용하는 기계를 만들었고, 각 칩은 정해진 범위에 속하는 모든 키를 가지고 암호화된 데이터를 풀려고 시도했다. 그리고 '흥미로운' 결과가 나오면 컨트롤러에게 보내서 더 자세히 분석하게 했다. 이 기계는 키를 1초에 900억개 분석할 수 있었다. 





### 정리

7장은 컴퓨터 하드웨어를 이용해 데이터를 더 잘 조직화 하는 방법을 소개했다. 8장에서는 프로그램을 어떻게 컴퓨터 하드웽어가 이해할 수 있는 형태로 변환할 수 있는지 살펴본다.

